{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and evaluate forward models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ae6c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd846cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read te data and split it\n",
    "resmat = pd.read_excel(\"te_results_expanded.xlsx\")\n",
    "X = resmat.iloc[:,:4]*(10**9)\n",
    "Y = resmat.iloc[:,11:]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42);\n",
    "X_train_1, X_test_1, Y_train_1, Y_test_1 = train_test_split(X, Y, random_state=None);\n",
    "X_train_2, X_test_2, Y_train_2, Y_test_2 = train_test_split(X, Y, random_state=None);\n",
    "X_train_3, X_test_3, Y_train_3, Y_test_3 = train_test_split(X, Y, random_state=None);\n",
    "X_train_4, X_test_4, Y_train_4, Y_test_4 = train_test_split(X, Y, random_state=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb4d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale train and test data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test_1 = scaler.transform(X_test_1)\n",
    "X_test_2 = scaler.transform(X_test_2)\n",
    "X_test_3 = scaler.transform(X_test_3)\n",
    "X_test_4 = scaler.transform(X_test_4)\n",
    "r = np.amax(X_train, axis = 0) - np.amin(X_train, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80089d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(alpha=0.05, hidden_layer_sizes=(100, 100, 100), max_iter=2000,\n",
       "             solver='lbfgs')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train reference model - 3 hidden layers of 100 neurons each, 2000 iterations\n",
    "nn_ref = MLPRegressor(solver=\"lbfgs\", max_iter=2000, alpha=0.05, hidden_layer_sizes=(100,100,100))\n",
    "nn_ref.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f76b352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9748473466049543\n",
      "[0.9360238323811996, 0.9842950817877529, 0.9883541304023766, 0.985827174786652, 0.9797365136667902]\n"
     ]
    }
   ],
   "source": [
    "#evaluate reference model\n",
    "ref_score = [nn_ref.score(X_test, Y_test), nn_ref.score(X_test_1, Y_test_1), nn_ref.score(X_test_2, Y_test_2),\n",
    "            nn_ref.score(X_test_3, Y_test_3), nn_ref.score(X_test_4, Y_test_4)]\n",
    "print(np.average(ref_score))\n",
    "print(ref_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a089812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a list of neuron layers build\n",
    "def hls_list(min_l=2, max_l=5, step_l=1, min_n=100, max_n=500, step_n=100):\n",
    "    hls = list()\n",
    "    for layer in np.arange(min_l, max_l+1, step_l):\n",
    "        for neuron in np.arange(min_n, max_n+1, step_n):\n",
    "            tup = tuple()\n",
    "            for i in range(layer):\n",
    "                tup = tup + (neuron,)\n",
    "            hls.append(tup)\n",
    "    return hls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a133d67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try 1:\n",
      "{'mean_fit_time': array([ 0.3246253 ,  0.43726282,  0.49887009,  0.47664142,  0.96899858,\n",
      "        1.88813567,  1.33654442,  1.71468801,  1.7531714 ,  2.35195751,\n",
      "        1.82838717,  1.08775401,  2.02082634,  1.37387171,  1.35472431,\n",
      "        1.356251  ,  0.90926023,  1.7850924 ,  2.40522656,  2.13513284,\n",
      "        2.23866258,  5.3689784 ,  5.88548594,  7.20464468,  4.29617844,\n",
      "        9.34144254, 10.88563285, 11.78057323, 10.11712661, 14.70314584,\n",
      "       18.71971383, 21.32048969]), 'std_fit_time': array([3.54795051e-02, 1.15089671e-01, 9.62543526e-02, 1.12231351e-01,\n",
      "       2.14677431e-01, 3.61524586e-01, 2.74731091e-01, 2.79271370e-01,\n",
      "       2.74331244e-01, 7.33850024e-01, 2.83628033e-01, 1.12307131e-01,\n",
      "       4.34345730e-01, 3.04370699e-01, 4.60460492e-01, 1.64115920e-01,\n",
      "       8.59036373e-03, 8.67201667e-02, 4.39869166e-01, 5.71963175e-01,\n",
      "       4.15650493e-02, 7.59336251e-01, 2.74341255e+00, 2.19852364e+00,\n",
      "       1.96556942e-01, 9.17659710e-01, 6.83789548e+00, 5.39465516e+00,\n",
      "       9.86561031e-01, 3.64424319e+00, 3.56885516e+00, 1.06849606e+01]), 'mean_score_time': array([0.00182734, 0.00116868, 0.00120878, 0.00125771, 0.00263443,\n",
      "       0.00336242, 0.00323243, 0.00322475, 0.00408649, 0.00430641,\n",
      "       0.00288944, 0.00192652, 0.00343838, 0.00192399, 0.00179262,\n",
      "       0.00155339, 0.00201855, 0.00193563, 0.00198512, 0.00168281,\n",
      "       0.00245914, 0.00273156, 0.00268898, 0.0036006 , 0.00262251,\n",
      "       0.00308647, 0.00314236, 0.00318518, 0.00467381, 0.00403061,\n",
      "       0.00387058, 0.00451159]), 'std_score_time': array([1.09050287e-03, 3.72709784e-05, 1.98858818e-05, 6.01328146e-05,\n",
      "       9.93683980e-04, 4.53140361e-04, 2.87998014e-04, 2.87077141e-04,\n",
      "       7.80750468e-04, 7.54652068e-04, 6.64003788e-04, 2.62932808e-04,\n",
      "       1.26055810e-03, 3.48829877e-04, 4.29155122e-04, 1.15483581e-04,\n",
      "       8.99050634e-05, 2.15829403e-04, 2.99220062e-04, 7.37479808e-05,\n",
      "       9.95139385e-05, 4.68127944e-04, 7.51316838e-04, 1.20697345e-03,\n",
      "       2.72886644e-04, 4.44004625e-04, 8.02565087e-04, 5.67931504e-04,\n",
      "       6.17187533e-04, 4.25446784e-04, 1.95816336e-04, 4.49924375e-04]), 'param_hidden_layer_sizes': masked_array(data=[(50,), (50,), (50,), (50,), (100,), (100,), (100,),\n",
      "                   (100,), (150,), (150,), (150,), (150,), (200,), (200,),\n",
      "                   (200,), (200,), (50, 50), (50, 50), (50, 50), (50, 50),\n",
      "                   (100, 100), (100, 100), (100, 100), (100, 100),\n",
      "                   (150, 150), (150, 150), (150, 150), (150, 150),\n",
      "                   (200, 200), (200, 200), (200, 200), (200, 200)],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_iter': masked_array(data=[500, 1000, 1500, 2000, 500, 1000, 1500, 2000, 500,\n",
      "                   1000, 1500, 2000, 500, 1000, 1500, 2000, 500, 1000,\n",
      "                   1500, 2000, 500, 1000, 1500, 2000, 500, 1000, 1500,\n",
      "                   2000, 500, 1000, 1500, 2000],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'hidden_layer_sizes': (50,), 'max_iter': 500}, {'hidden_layer_sizes': (50,), 'max_iter': 1000}, {'hidden_layer_sizes': (50,), 'max_iter': 1500}, {'hidden_layer_sizes': (50,), 'max_iter': 2000}, {'hidden_layer_sizes': (100,), 'max_iter': 500}, {'hidden_layer_sizes': (100,), 'max_iter': 1000}, {'hidden_layer_sizes': (100,), 'max_iter': 1500}, {'hidden_layer_sizes': (100,), 'max_iter': 2000}, {'hidden_layer_sizes': (150,), 'max_iter': 500}, {'hidden_layer_sizes': (150,), 'max_iter': 1000}, {'hidden_layer_sizes': (150,), 'max_iter': 1500}, {'hidden_layer_sizes': (150,), 'max_iter': 2000}, {'hidden_layer_sizes': (200,), 'max_iter': 500}, {'hidden_layer_sizes': (200,), 'max_iter': 1000}, {'hidden_layer_sizes': (200,), 'max_iter': 1500}, {'hidden_layer_sizes': (200,), 'max_iter': 2000}, {'hidden_layer_sizes': (50, 50), 'max_iter': 500}, {'hidden_layer_sizes': (50, 50), 'max_iter': 1000}, {'hidden_layer_sizes': (50, 50), 'max_iter': 1500}, {'hidden_layer_sizes': (50, 50), 'max_iter': 2000}, {'hidden_layer_sizes': (100, 100), 'max_iter': 500}, {'hidden_layer_sizes': (100, 100), 'max_iter': 1000}, {'hidden_layer_sizes': (100, 100), 'max_iter': 1500}, {'hidden_layer_sizes': (100, 100), 'max_iter': 2000}, {'hidden_layer_sizes': (150, 150), 'max_iter': 500}, {'hidden_layer_sizes': (150, 150), 'max_iter': 1000}, {'hidden_layer_sizes': (150, 150), 'max_iter': 1500}, {'hidden_layer_sizes': (150, 150), 'max_iter': 2000}, {'hidden_layer_sizes': (200, 200), 'max_iter': 500}, {'hidden_layer_sizes': (200, 200), 'max_iter': 1000}, {'hidden_layer_sizes': (200, 200), 'max_iter': 1500}, {'hidden_layer_sizes': (200, 200), 'max_iter': 2000}], 'split0_test_score': array([0.74007306, 0.75889809, 0.79031773, 0.74150595, 0.74208039,\n",
      "       0.78408532, 0.77102676, 0.76060588, 0.75529728, 0.76769531,\n",
      "       0.74915898, 0.76129609, 0.78384046, 0.7624    , 0.7616771 ,\n",
      "       0.75033264, 0.83530168, 0.82673586, 0.81635182, 0.82259818,\n",
      "       0.80004358, 0.82127186, 0.81469265, 0.84854304, 0.79773927,\n",
      "       0.82975686, 0.83727784, 0.83435921, 0.81124564, 0.81902705,\n",
      "       0.85557029, 0.78971212]), 'split1_test_score': array([0.74517123, 0.72582831, 0.7354946 , 0.74872143, 0.77301422,\n",
      "       0.7717253 , 0.78020132, 0.78260586, 0.780956  , 0.76921184,\n",
      "       0.77427759, 0.78072525, 0.77571939, 0.78884797, 0.78508242,\n",
      "       0.7953343 , 0.82629162, 0.83776325, 0.84900247, 0.81532269,\n",
      "       0.83503327, 0.81385695, 0.8463046 , 0.85062954, 0.83112993,\n",
      "       0.85798876, 0.85598315, 0.84167213, 0.84252266, 0.85010799,\n",
      "       0.85283984, 0.84218443]), 'split2_test_score': array([0.70207557, 0.77721805, 0.74753765, 0.78947799, 0.81100862,\n",
      "       0.82161891, 0.78273831, 0.79837054, 0.78955156, 0.78115913,\n",
      "       0.79715352, 0.79194393, 0.80631943, 0.82506289, 0.8116789 ,\n",
      "       0.81207725, 0.85536674, 0.81568371, 0.88201309, 0.89646562,\n",
      "       0.87600545, 0.86255821, 0.88141828, 0.87336187, 0.85949704,\n",
      "       0.86336668, 0.87298776, 0.87393242, 0.87423467, 0.85644659,\n",
      "       0.86982395, 0.88307174]), 'split3_test_score': array([0.78758949, 0.82705845, 0.8073748 , 0.81964429, 0.84561277,\n",
      "       0.81388887, 0.81325031, 0.82101946, 0.80841068, 0.81365706,\n",
      "       0.79880299, 0.800672  , 0.8287188 , 0.83857819, 0.80781469,\n",
      "       0.83418679, 0.85715929, 0.86105466, 0.87302711, 0.84356837,\n",
      "       0.87562379, 0.90308392, 0.88567654, 0.89562442, 0.87199797,\n",
      "       0.88404545, 0.88764249, 0.89247452, 0.87875149, 0.89325897,\n",
      "       0.88926441, 0.90019386]), 'split4_test_score': array([0.79769125, 0.81519089, 0.80441607, 0.81865211, 0.83595215,\n",
      "       0.83284237, 0.81892654, 0.82404223, 0.83936481, 0.84933236,\n",
      "       0.83100843, 0.84269973, 0.84440674, 0.84268597, 0.84433172,\n",
      "       0.83154019, 0.85013472, 0.88538726, 0.89951644, 0.86118366,\n",
      "       0.89687528, 0.88907069, 0.90441602, 0.90349969, 0.90030126,\n",
      "       0.90810105, 0.88615712, 0.8988308 , 0.90197505, 0.91708046,\n",
      "       0.90873341, 0.9100325 ]), 'mean_test_score': array([0.75452012, 0.78083876, 0.77702817, 0.78360035, 0.80153363,\n",
      "       0.80483215, 0.79322865, 0.79732879, 0.79471606, 0.79621114,\n",
      "       0.7900803 , 0.7954674 , 0.80780096, 0.81151501, 0.80211697,\n",
      "       0.80469424, 0.84485081, 0.84532495, 0.86398218, 0.84782771,\n",
      "       0.85671627, 0.85796833, 0.86650162, 0.87433171, 0.85213309,\n",
      "       0.86865176, 0.86800967, 0.86825381, 0.8617459 , 0.86718421,\n",
      "       0.87524638, 0.86503893]), 'std_test_score': array([0.03465222, 0.03697832, 0.02980723, 0.03331911, 0.03889839,\n",
      "       0.02312957, 0.01915166, 0.02383811, 0.02811016, 0.03128866,\n",
      "       0.02729655, 0.02703851, 0.02601179, 0.03102795, 0.02768226,\n",
      "       0.03061966, 0.01204685, 0.02503497, 0.0288536 , 0.02917285,\n",
      "       0.03471098, 0.03554233, 0.0319993 , 0.02250306, 0.03512502,\n",
      "       0.02625893, 0.01912402, 0.02611234, 0.03157009, 0.03433813,\n",
      "       0.02114942, 0.04423105]), 'rank_test_score': array([32, 30, 31, 29, 22, 19, 27, 23, 26, 24, 28, 25, 18, 17, 21, 20, 16,\n",
      "       15,  9, 14, 12, 11,  7,  2, 13,  3,  5,  4, 10,  6,  1,  8],\n",
      "      dtype=int32)}\n",
      "MLPRegressor(alpha=0.05, hidden_layer_sizes=(200, 200), max_iter=1500,\n",
      "             solver='lbfgs')\n",
      "0.8752463791905145\n",
      "{'hidden_layer_sizes': (200, 200), 'max_iter': 1500}\n"
     ]
    }
   ],
   "source": [
    "#performing grid search to avoid overfitting - try 1\n",
    "hls = hls_list(1,2,1,50,200,50)\n",
    "m = [500, 1000, 1500, 2000]\n",
    "\n",
    "par = {'hidden_layer_sizes':hls, 'max_iter':m}\n",
    "\n",
    "nnl = MLPRegressor(solver=\"lbfgs\", alpha=0.05)\n",
    "regl_1 = GridSearchCV(nnl, par, scoring='r2', cv=5)\n",
    "regl_1.fit(X_train,Y_train)\n",
    "print(\"try 1:\")\n",
    "print(regl_1.cv_results_)\n",
    "print(regl_1.best_estimator_)\n",
    "print(regl_1.best_score_)\n",
    "print(regl_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02184676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try 2:\n",
      "{'mean_fit_time': array([15.15140877, 18.08903751, 22.0727005 , 24.18199754, 27.87906919,\n",
      "       22.57065616, 33.74746666, 30.58345633, 30.11135464, 54.33476934,\n",
      "       73.72442641, 58.67354488, 47.28341846, 58.62878842, 72.60872078,\n",
      "       44.08027444, 62.21064434, 85.25748281]), 'std_fit_time': array([ 3.08955836,  6.96478191,  8.83494793,  5.85080198,  4.71681441,\n",
      "        4.00951626,  6.89255854,  7.94515417, 10.10560839, 28.86680888,\n",
      "       21.30248806, 13.67868625, 17.28837371, 17.72262803, 26.97403616,\n",
      "       29.77244985, 18.33223289, 43.18743468]), 'mean_score_time': array([0.00250392, 0.00345225, 0.00426769, 0.0091136 , 0.00456285,\n",
      "       0.00308843, 0.00358877, 0.00330915, 0.00665054, 0.01387067,\n",
      "       0.01554575, 0.00866346, 0.00509391, 0.00804529, 0.020963  ,\n",
      "       0.00556045, 0.00628715, 0.0070159 ]), 'std_score_time': array([2.77503552e-04, 8.41969997e-04, 1.41399542e-03, 6.52679804e-03,\n",
      "       2.46170943e-03, 3.31137229e-05, 5.69448322e-04, 6.28497922e-04,\n",
      "       3.72999026e-03, 5.31464588e-03, 4.99110479e-03, 4.54182625e-03,\n",
      "       2.30271650e-03, 5.21645827e-03, 1.75802802e-02, 1.94120217e-03,\n",
      "       2.59020574e-03, 2.37020892e-03]), 'param_hidden_layer_sizes': masked_array(data=[(200, 200), (200, 200), (200, 200), (250, 250),\n",
      "                   (250, 250), (250, 250), (300, 300), (300, 300),\n",
      "                   (300, 300), (200, 200, 200), (200, 200, 200),\n",
      "                   (200, 200, 200), (250, 250, 250), (250, 250, 250),\n",
      "                   (250, 250, 250), (300, 300, 300), (300, 300, 300),\n",
      "                   (300, 300, 300)],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_iter': masked_array(data=[1500, 2000, 2500, 1500, 2000, 2500, 1500, 2000, 2500,\n",
      "                   1500, 2000, 2500, 1500, 2000, 2500, 1500, 2000, 2500],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'hidden_layer_sizes': (200, 200), 'max_iter': 1500}, {'hidden_layer_sizes': (200, 200), 'max_iter': 2000}, {'hidden_layer_sizes': (200, 200), 'max_iter': 2500}, {'hidden_layer_sizes': (250, 250), 'max_iter': 1500}, {'hidden_layer_sizes': (250, 250), 'max_iter': 2000}, {'hidden_layer_sizes': (250, 250), 'max_iter': 2500}, {'hidden_layer_sizes': (300, 300), 'max_iter': 1500}, {'hidden_layer_sizes': (300, 300), 'max_iter': 2000}, {'hidden_layer_sizes': (300, 300), 'max_iter': 2500}, {'hidden_layer_sizes': (200, 200, 200), 'max_iter': 1500}, {'hidden_layer_sizes': (200, 200, 200), 'max_iter': 2000}, {'hidden_layer_sizes': (200, 200, 200), 'max_iter': 2500}, {'hidden_layer_sizes': (250, 250, 250), 'max_iter': 1500}, {'hidden_layer_sizes': (250, 250, 250), 'max_iter': 2000}, {'hidden_layer_sizes': (250, 250, 250), 'max_iter': 2500}, {'hidden_layer_sizes': (300, 300, 300), 'max_iter': 1500}, {'hidden_layer_sizes': (300, 300, 300), 'max_iter': 2000}, {'hidden_layer_sizes': (300, 300, 300), 'max_iter': 2500}], 'split0_test_score': array([0.86110158, 0.84361751, 0.84205914, 0.82907469, 0.83069438,\n",
      "       0.86727123, 0.83413731, 0.84806365, 0.83983424, 0.70664667,\n",
      "       0.88299793, 0.87043836, 0.84812301, 0.84889802, 0.83865733,\n",
      "       0.73646818, 0.76215408, 0.74378743]), 'split1_test_score': array([0.83720982, 0.8450434 , 0.84916328, 0.84321748, 0.84377962,\n",
      "       0.83868359, 0.84778578, 0.85819433, 0.85127985, 0.86603636,\n",
      "       0.86519839, 0.87725424, 0.85595392, 0.87135033, 0.87631117,\n",
      "       0.79088224, 0.83240504, 0.86884657]), 'split2_test_score': array([0.88477726, 0.89219937, 0.87433535, 0.90173967, 0.87945128,\n",
      "       0.90342351, 0.86855702, 0.88314006, 0.86668225, 0.91267992,\n",
      "       0.87056445, 0.88825509, 0.90008908, 0.9092717 , 0.86663448,\n",
      "       0.88536723, 0.8471251 , 0.89650901]), 'split3_test_score': array([0.90063271, 0.88808663, 0.89282627, 0.89715286, 0.89501582,\n",
      "       0.88650632, 0.89458893, 0.89891738, 0.91625664, 0.91477511,\n",
      "       0.91309677, 0.92323277, 0.89665775, 0.91888063, 0.91928807,\n",
      "       0.92244103, 0.92943352, 0.71808197]), 'split4_test_score': array([0.91222351, 0.92009222, 0.91616306, 0.91116475, 0.90083819,\n",
      "       0.91112941, 0.9062812 , 0.90584732, 0.91207953, 0.90953347,\n",
      "       0.92796895, 0.9214814 , 0.88091561, 0.92324281, 0.92487176,\n",
      "       0.93183246, 0.8726652 , 0.91658938]), 'mean_test_score': array([0.87918898, 0.87780783, 0.87490942, 0.87646989, 0.86995586,\n",
      "       0.88140281, 0.87027005, 0.87883255, 0.8772265 , 0.86193431,\n",
      "       0.8919653 , 0.89613237, 0.87634787, 0.8943287 , 0.88515256,\n",
      "       0.85339823, 0.84875659, 0.82876288]), 'std_test_score': array([0.02709888, 0.02947279, 0.02744161, 0.0335324 , 0.02792326,\n",
      "       0.02615057, 0.02721126, 0.0224696 , 0.03137093, 0.07970449,\n",
      "       0.02448542, 0.02216133, 0.02102169, 0.02916871, 0.03263662,\n",
      "       0.07683976, 0.05449847, 0.0817078 ]), 'rank_test_score': array([ 6,  8, 12, 10, 14,  5, 13,  7,  9, 15,  3,  1, 11,  2,  4, 16, 17,\n",
      "       18], dtype=int32)}\n",
      "MLPRegressor(alpha=0.05, hidden_layer_sizes=(200, 200, 200), max_iter=2500,\n",
      "             solver='lbfgs')\n",
      "0.8961323733768044\n",
      "{'hidden_layer_sizes': (200, 200, 200), 'max_iter': 2500}\n"
     ]
    }
   ],
   "source": [
    "#performing grid search to avoid overfitting - try 2\n",
    "hls = hls_list(2,3,1,200,300,50)\n",
    "m = [1500, 2000, 2500]\n",
    "\n",
    "par = {'hidden_layer_sizes':hls, 'max_iter':m}\n",
    "\n",
    "nnl = MLPRegressor(solver=\"lbfgs\", alpha=0.05)\n",
    "regl_2 = GridSearchCV(nnl, par, scoring='r2', cv=5)\n",
    "regl_2.fit(X_train,Y_train)\n",
    "print(\"try 2:\")\n",
    "print(regl_2.cv_results_)\n",
    "print(regl_2.best_estimator_)\n",
    "print(regl_2.best_score_)\n",
    "print(regl_2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3915ed3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try 3:\n",
      "{'mean_fit_time': array([13.0669126 , 14.34315119, 25.83606062, 50.39467111, 43.16744418,\n",
      "       22.38325934, 63.23605661, 72.15729203, 39.66496468, 27.35567698,\n",
      "       20.81710725, 25.32994657, 30.11467423, 27.84062929, 30.56554132,\n",
      "       48.42050185, 68.09980478, 30.50612893, 32.41342559, 38.35310898,\n",
      "       32.77008748, 27.5886436 , 52.00957966, 43.96108675, 65.25351062,\n",
      "       77.90748363, 74.84626422]), 'std_fit_time': array([ 0.39778051,  5.23666228, 11.64311001,  8.75578347,  5.91270183,\n",
      "       10.14932535, 16.65931857, 21.53650697, 12.37809267,  6.08220503,\n",
      "       10.22717263, 12.41576009, 15.46537392, 15.00156341, 15.69287314,\n",
      "       32.17316442, 19.81837453, 19.28854435, 15.15476647, 13.8241517 ,\n",
      "       20.85097224,  8.22124864, 22.60408311, 25.96696392, 42.76218105,\n",
      "       39.26318028, 42.34638132]), 'mean_score_time': array([0.00255299, 0.00640736, 0.009094  , 0.00997453, 0.01086202,\n",
      "       0.00282803, 0.00668001, 0.00344777, 0.00392842, 0.00249839,\n",
      "       0.00232277, 0.00314388, 0.00326257, 0.00299673, 0.00287967,\n",
      "       0.00394869, 0.00361476, 0.00421886, 0.002424  , 0.00249205,\n",
      "       0.00233159, 0.00345321, 0.00300455, 0.00336332, 0.00529399,\n",
      "       0.00433202, 0.00464101]), 'std_score_time': array([9.04910397e-04, 3.15306813e-03, 6.24452948e-03, 4.02067384e-03,\n",
      "       3.49145081e-03, 2.57987041e-04, 3.19371989e-03, 6.43502707e-04,\n",
      "       1.58636414e-03, 5.17185548e-04, 1.43661833e-04, 1.54744883e-03,\n",
      "       6.83591102e-04, 3.86141789e-04, 3.89485495e-04, 5.11943774e-04,\n",
      "       4.73713865e-04, 9.12361189e-04, 1.65151846e-04, 1.89672168e-04,\n",
      "       4.78426193e-05, 5.45123326e-04, 1.58602734e-04, 6.47600169e-04,\n",
      "       6.87788264e-04, 5.56104319e-04, 9.60220725e-04]), 'param_hidden_layer_sizes': masked_array(data=[(150, 150, 150), (150, 150, 150), (150, 150, 150),\n",
      "                   (200, 200, 200), (200, 200, 200), (200, 200, 200),\n",
      "                   (250, 250, 250), (250, 250, 250), (250, 250, 250),\n",
      "                   (150, 150, 150, 150), (150, 150, 150, 150),\n",
      "                   (150, 150, 150, 150), (200, 200, 200, 200),\n",
      "                   (200, 200, 200, 200), (200, 200, 200, 200),\n",
      "                   (250, 250, 250, 250), (250, 250, 250, 250),\n",
      "                   (250, 250, 250, 250), (150, 150, 150, 150, 150),\n",
      "                   (150, 150, 150, 150, 150), (150, 150, 150, 150, 150),\n",
      "                   (200, 200, 200, 200, 200), (200, 200, 200, 200, 200),\n",
      "                   (200, 200, 200, 200, 200), (250, 250, 250, 250, 250),\n",
      "                   (250, 250, 250, 250, 250), (250, 250, 250, 250, 250)],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_iter': masked_array(data=[2500, 3000, 3500, 2500, 3000, 3500, 2500, 3000, 3500,\n",
      "                   2500, 3000, 3500, 2500, 3000, 3500, 2500, 3000, 3500,\n",
      "                   2500, 3000, 3500, 2500, 3000, 3500, 2500, 3000, 3500],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'hidden_layer_sizes': (150, 150, 150), 'max_iter': 2500}, {'hidden_layer_sizes': (150, 150, 150), 'max_iter': 3000}, {'hidden_layer_sizes': (150, 150, 150), 'max_iter': 3500}, {'hidden_layer_sizes': (200, 200, 200), 'max_iter': 2500}, {'hidden_layer_sizes': (200, 200, 200), 'max_iter': 3000}, {'hidden_layer_sizes': (200, 200, 200), 'max_iter': 3500}, {'hidden_layer_sizes': (250, 250, 250), 'max_iter': 2500}, {'hidden_layer_sizes': (250, 250, 250), 'max_iter': 3000}, {'hidden_layer_sizes': (250, 250, 250), 'max_iter': 3500}, {'hidden_layer_sizes': (150, 150, 150, 150), 'max_iter': 2500}, {'hidden_layer_sizes': (150, 150, 150, 150), 'max_iter': 3000}, {'hidden_layer_sizes': (150, 150, 150, 150), 'max_iter': 3500}, {'hidden_layer_sizes': (200, 200, 200, 200), 'max_iter': 2500}, {'hidden_layer_sizes': (200, 200, 200, 200), 'max_iter': 3000}, {'hidden_layer_sizes': (200, 200, 200, 200), 'max_iter': 3500}, {'hidden_layer_sizes': (250, 250, 250, 250), 'max_iter': 2500}, {'hidden_layer_sizes': (250, 250, 250, 250), 'max_iter': 3000}, {'hidden_layer_sizes': (250, 250, 250, 250), 'max_iter': 3500}, {'hidden_layer_sizes': (150, 150, 150, 150, 150), 'max_iter': 2500}, {'hidden_layer_sizes': (150, 150, 150, 150, 150), 'max_iter': 3000}, {'hidden_layer_sizes': (150, 150, 150, 150, 150), 'max_iter': 3500}, {'hidden_layer_sizes': (200, 200, 200, 200, 200), 'max_iter': 2500}, {'hidden_layer_sizes': (200, 200, 200, 200, 200), 'max_iter': 3000}, {'hidden_layer_sizes': (200, 200, 200, 200, 200), 'max_iter': 3500}, {'hidden_layer_sizes': (250, 250, 250, 250, 250), 'max_iter': 2500}, {'hidden_layer_sizes': (250, 250, 250, 250, 250), 'max_iter': 3000}, {'hidden_layer_sizes': (250, 250, 250, 250, 250), 'max_iter': 3500}], 'split0_test_score': array([0.86887056, 0.88166084, 0.70822261, 0.8536319 , 0.7716009 ,\n",
      "       0.79597503, 0.85650001, 0.8763149 , 0.7949865 , 0.8598901 ,\n",
      "       0.86219897, 0.86548517, 0.85649802, 0.75966568, 0.78589795,\n",
      "       0.68225816, 0.79607768, 0.88217124, 0.87962339, 0.8726248 ,\n",
      "       0.86934984, 0.74703857, 0.8893804 , 0.87846089, 0.87107986,\n",
      "       0.86982958, 0.82394668]), 'split1_test_score': array([0.87018101, 0.85472764, 0.86133851, 0.87843575, 0.86236303,\n",
      "       0.8424967 , 0.88047424, 0.87713838, 0.84836241, 0.87228479,\n",
      "       0.85392581, 0.88698814, 0.85438109, 0.88281605, 0.88129122,\n",
      "       0.8666402 , 0.87133825, 0.77861553, 0.87913905, 0.89035001,\n",
      "       0.79550887, 0.83171014, 0.88752165, 0.88887442, 0.88785589,\n",
      "       0.83120158, 0.79200431]), 'split2_test_score': array([0.89407108, 0.88926126, 0.88161614, 0.90552537, 0.91138365,\n",
      "       0.92294967, 0.88415484, 0.90042063, 0.91134411, 0.92061246,\n",
      "       0.92022075, 0.91055343, 0.91467416, 0.87912599, 0.91358898,\n",
      "       0.85494255, 0.89692524, 0.8125328 , 0.8695249 , 0.89122033,\n",
      "       0.90112413, 0.88199985, 0.92994648, 0.90549186, 0.86252699,\n",
      "       0.87690395, 0.91045589]), 'split3_test_score': array([0.90910439, 0.93200827, 0.9194591 , 0.92125483, 0.92214856,\n",
      "       0.91325804, 0.91363476, 0.91427495, 0.92421247, 0.93016491,\n",
      "       0.9277193 , 0.91362093, 0.78384474, 0.82911706, 0.76770752,\n",
      "       0.90548015, 0.88456676, 0.91765987, 0.93825258, 0.93381061,\n",
      "       0.88452231, 0.82787778, 0.83845637, 0.89038233, 0.61502229,\n",
      "       0.92643873, 0.91557033]), 'split4_test_score': array([0.9168823 , 0.89508998, 0.92088623, 0.91005008, 0.92225367,\n",
      "       0.92511444, 0.91599275, 0.93568186, 0.92309098, 0.92962738,\n",
      "       0.90278278, 0.88519912, 0.8965037 , 0.90592263, 0.88958126,\n",
      "       0.91944249, 0.92284351, 0.86049397, 0.83823172, 0.92402123,\n",
      "       0.92072855, 0.89636265, 0.91538753, 0.85263859, 0.8506271 ,\n",
      "       0.92422582, 0.88011734]), 'mean_test_score': array([0.89182187, 0.8905496 , 0.85830452, 0.89377959, 0.87794996,\n",
      "       0.87995878, 0.89015132, 0.90076614, 0.88039929, 0.90251593,\n",
      "       0.89336952, 0.89236936, 0.86118034, 0.85132948, 0.84761339,\n",
      "       0.84575271, 0.87435029, 0.85029468, 0.88095433, 0.9024054 ,\n",
      "       0.87424674, 0.8369978 , 0.89213848, 0.88316962, 0.81742243,\n",
      "       0.88571993, 0.86441891]), 'std_test_score': array([0.01963089, 0.02491312, 0.07840098, 0.02451469, 0.05759726,\n",
      "       0.05187055, 0.02227674, 0.02261791, 0.05103227, 0.03019227,\n",
      "       0.03005633, 0.01780685, 0.04507389, 0.05223046, 0.05906271,\n",
      "       0.08514547, 0.04266444, 0.04944102, 0.03238521, 0.02285105,\n",
      "       0.04292359, 0.05244648, 0.03124309, 0.01753378, 0.10192427,\n",
      "       0.03589763, 0.04871178]), 'rank_test_score': array([ 8,  9, 21,  4, 16, 15, 10,  3, 14,  1,  5,  6, 20, 22, 24, 25, 17,\n",
      "       23, 13,  2, 18, 26,  7, 12, 27, 11, 19], dtype=int32)}\n",
      "MLPRegressor(alpha=0.05, hidden_layer_sizes=(150, 150, 150, 150), max_iter=2500,\n",
      "             solver='lbfgs')\n",
      "0.902515928732998\n",
      "{'hidden_layer_sizes': (150, 150, 150, 150), 'max_iter': 2500}\n"
     ]
    }
   ],
   "source": [
    "#performing grid search to avoid overfitting - try 3\n",
    "hls = hls_list(3,5,1,150,250,50)\n",
    "m = [2500, 3000, 3500]\n",
    "\n",
    "par = {'hidden_layer_sizes':hls, 'max_iter':m}\n",
    "\n",
    "nnl = MLPRegressor(solver=\"lbfgs\", alpha=0.05)\n",
    "regl_3 = GridSearchCV(nnl, par, scoring='r2', cv=5)\n",
    "regl_3.fit(X_train,Y_train)\n",
    "print(\"try 3:\")\n",
    "print(regl_3.cv_results_)\n",
    "print(regl_3.best_estimator_)\n",
    "print(regl_3.best_score_)\n",
    "print(regl_3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eca4de78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try 4:\n",
      "{'mean_fit_time': array([  11.18047872,   16.52513947,   21.26043253,   11.72050705,\n",
      "         34.19396777,   65.36960411,  139.30296278,  602.77357969,\n",
      "       1037.7651176 ]), 'std_fit_time': array([  1.45251317,   4.80867274,  15.34523499,   4.11309325,\n",
      "        12.50355919,  30.81954299, 156.2919761 , 321.66050306,\n",
      "        58.08755037]), 'mean_score_time': array([0.00153961, 0.00246511, 0.00309415, 0.0019114 , 0.00357766,\n",
      "       0.00407867, 0.00243506, 0.00210838, 0.00367398]), 'std_score_time': array([0.00021529, 0.00070169, 0.00052983, 0.00016124, 0.00149929,\n",
      "       0.00166882, 0.00140278, 0.00025282, 0.00055812]), 'param_hidden_layer_sizes': masked_array(data=[(100, 100, 100, 100), (150, 150, 150, 150),\n",
      "                   (200, 200, 200, 200), (100, 100, 100, 100, 100),\n",
      "                   (150, 150, 150, 150, 150), (200, 200, 200, 200, 200),\n",
      "                   (100, 100, 100, 100, 100, 100),\n",
      "                   (150, 150, 150, 150, 150, 150),\n",
      "                   (200, 200, 200, 200, 200, 200)],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_iter': masked_array(data=[2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'hidden_layer_sizes': (100, 100, 100, 100), 'max_iter': 2500}, {'hidden_layer_sizes': (150, 150, 150, 150), 'max_iter': 2500}, {'hidden_layer_sizes': (200, 200, 200, 200), 'max_iter': 2500}, {'hidden_layer_sizes': (100, 100, 100, 100, 100), 'max_iter': 2500}, {'hidden_layer_sizes': (150, 150, 150, 150, 150), 'max_iter': 2500}, {'hidden_layer_sizes': (200, 200, 200, 200, 200), 'max_iter': 2500}, {'hidden_layer_sizes': (100, 100, 100, 100, 100, 100), 'max_iter': 2500}, {'hidden_layer_sizes': (150, 150, 150, 150, 150, 150), 'max_iter': 2500}, {'hidden_layer_sizes': (200, 200, 200, 200, 200, 200), 'max_iter': 2500}], 'split0_test_score': array([0.87381372, 0.88545677, 0.78284682, 0.85417966, 0.8842583 ,\n",
      "       0.87148827, 0.84848637, 0.87808545, 0.87773261]), 'split1_test_score': array([0.8903485 , 0.88280136, 0.87915478, 0.88646479, 0.88079495,\n",
      "       0.82054924, 0.89937862, 0.91467488, 0.82423723]), 'split2_test_score': array([0.89760662, 0.91435683, 0.80462011, 0.89180993, 0.90093567,\n",
      "       0.92996802, 0.90498512, 0.8784508 , 0.85728934]), 'split3_test_score': array([0.92899964, 0.92488314, 0.85121389, 0.93845194, 0.92033435,\n",
      "       0.94225798, 0.87181298, 0.93719277, 0.94710562]), 'split4_test_score': array([0.91826582, 0.89450631, 0.84979382, 0.91307335, 0.90692671,\n",
      "       0.91596282, 0.91320167, 0.91223341, 0.91798862]), 'mean_test_score': array([0.90180686, 0.90040088, 0.83352589, 0.89679593, 0.89864999,\n",
      "       0.89604527, 0.88757295, 0.90412746, 0.88487068]), 'std_test_score': array([0.01971242, 0.01650434, 0.03482361, 0.02809952, 0.0146278 ,\n",
      "       0.04468954, 0.02398135, 0.02283745, 0.04349272]), 'rank_test_score': array([2, 3, 9, 5, 4, 6, 7, 1, 8], dtype=int32)}\n",
      "MLPRegressor(alpha=0.05, hidden_layer_sizes=(150, 150, 150, 150, 150, 150),\n",
      "             max_iter=2500, solver='lbfgs')\n",
      "0.9041274620135606\n",
      "{'hidden_layer_sizes': (150, 150, 150, 150, 150, 150), 'max_iter': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#performing grid search to avoid overfitting - try 4\n",
    "hls = hls_list(4,6,1,100,200,50)\n",
    "m = [2500]\n",
    "\n",
    "par = {'hidden_layer_sizes':hls, 'max_iter':m}\n",
    "\n",
    "nnl = MLPRegressor(solver=\"lbfgs\", alpha=0.05)\n",
    "regl_4 = GridSearchCV(nnl, par, scoring='r2', cv=5)\n",
    "regl_4.fit(X_train,Y_train)\n",
    "print(\"try 4:\")\n",
    "print(regl_4.cv_results_)\n",
    "print(regl_4.best_estimator_)\n",
    "print(regl_4.best_score_)\n",
    "print(regl_4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e13d5a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/saarpop/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try 4:\n",
      "{'mean_fit_time': array([24.74280643, 48.28605447, 90.15495782, 15.5260078 , 67.20590405,\n",
      "       66.69437609, 40.90457597, 45.83793764, 66.72627459]), 'std_fit_time': array([13.92383252, 27.19095461, 21.68199622,  5.73429847, 35.37222066,\n",
      "       57.74108561, 19.84205769, 41.34970151, 12.72315681]), 'mean_score_time': array([0.00370569, 0.00483351, 0.00625334, 0.00324039, 0.00424566,\n",
      "       0.00674081, 0.00485106, 0.00490036, 0.00883279]), 'std_score_time': array([0.00030255, 0.0017595 , 0.00196741, 0.00012285, 0.00024391,\n",
      "       0.00219144, 0.00261334, 0.00042364, 0.00336674]), 'param_hidden_layer_sizes': masked_array(data=[(100, 100, 100, 100, 100, 100),\n",
      "                   (150, 150, 150, 150, 150, 150),\n",
      "                   (200, 200, 200, 200, 200, 200),\n",
      "                   (100, 100, 100, 100, 100, 100, 100),\n",
      "                   (150, 150, 150, 150, 150, 150, 150),\n",
      "                   (200, 200, 200, 200, 200, 200, 200),\n",
      "                   (100, 100, 100, 100, 100, 100, 100, 100),\n",
      "                   (150, 150, 150, 150, 150, 150, 150, 150),\n",
      "                   (200, 200, 200, 200, 200, 200, 200, 200)],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_iter': masked_array(data=[2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'hidden_layer_sizes': (100, 100, 100, 100, 100, 100), 'max_iter': 2500}, {'hidden_layer_sizes': (150, 150, 150, 150, 150, 150), 'max_iter': 2500}, {'hidden_layer_sizes': (200, 200, 200, 200, 200, 200), 'max_iter': 2500}, {'hidden_layer_sizes': (100, 100, 100, 100, 100, 100, 100), 'max_iter': 2500}, {'hidden_layer_sizes': (150, 150, 150, 150, 150, 150, 150), 'max_iter': 2500}, {'hidden_layer_sizes': (200, 200, 200, 200, 200, 200, 200), 'max_iter': 2500}, {'hidden_layer_sizes': (100, 100, 100, 100, 100, 100, 100, 100), 'max_iter': 2500}, {'hidden_layer_sizes': (150, 150, 150, 150, 150, 150, 150, 150), 'max_iter': 2500}, {'hidden_layer_sizes': (200, 200, 200, 200, 200, 200, 200, 200), 'max_iter': 2500}], 'split0_test_score': array([0.77330922, 0.87394749, 0.88435803, 0.87408862, 0.79937004,\n",
      "       0.88285744, 0.85012871, 0.77695062, 0.79106002]), 'split1_test_score': array([0.89169959, 0.89580184, 0.88402112, 0.89959054, 0.88787145,\n",
      "       0.90518827, 0.90478734, 0.83908278, 0.82244564]), 'split2_test_score': array([0.92414309, 0.83673886, 0.88138891, 0.9199505 , 0.90906584,\n",
      "       0.87103962, 0.94148366, 0.90614301, 0.85246828]), 'split3_test_score': array([0.88844165, 0.92997795, 0.84238244, 0.87545859, 0.89160585,\n",
      "       0.85815634, 0.93068872, 0.94550749, 0.82517298]), 'split4_test_score': array([0.93644682, 0.88795915, 0.90243508, 0.8972803 , 0.91453326,\n",
      "       0.80385794, 0.91351615, 0.87315828, 0.86320194]), 'mean_test_score': array([0.88280807, 0.88488506, 0.87891711, 0.89327371, 0.88048929,\n",
      "       0.86421992, 0.90812092, 0.86816844, 0.83086977]), 'std_test_score': array([0.05776936, 0.03033045, 0.0197466 , 0.0170473 , 0.04179478,\n",
      "       0.03391933, 0.03170393, 0.0576454 , 0.02529862]), 'rank_test_score': array([4, 3, 6, 2, 5, 8, 1, 7, 9], dtype=int32)}\n",
      "MLPRegressor(alpha=0.05,\n",
      "             hidden_layer_sizes=(100, 100, 100, 100, 100, 100, 100, 100),\n",
      "             max_iter=2500, solver='lbfgs')\n",
      "0.9081209172232736\n",
      "{'hidden_layer_sizes': (100, 100, 100, 100, 100, 100, 100, 100), 'max_iter': 2500}\n"
     ]
    }
   ],
   "source": [
    "#performing grid search to avoid overfitting - try 5\n",
    "hls = hls_list(6,8,1,100,200,50)\n",
    "m = [2500]\n",
    "\n",
    "par = {'hidden_layer_sizes':hls, 'max_iter':m}\n",
    "\n",
    "nnl = MLPRegressor(solver=\"lbfgs\", alpha=0.05)\n",
    "regl_4 = GridSearchCV(nnl, par, scoring='r2', cv=5)\n",
    "regl_4.fit(X_train,Y_train)\n",
    "print(\"try 4:\")\n",
    "print(regl_4.cv_results_)\n",
    "print(regl_4.best_estimator_)\n",
    "print(regl_4.best_score_)\n",
    "print(regl_4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19641484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9123134845492042, 0.9821920903508647, 0.9847686293150402, 0.9789072798908485, 0.9766728780295398]\n",
      "[0.9409180786471779, 0.9867855858624113, 0.9912552914670985, 0.9829622076932718, 0.9852828124179065]\n",
      "[0.9201973822509346, 0.968763633644312, 0.9680110533803286, 0.966993723786988, 0.966844084164532]\n",
      "[0.9555624457632991, 0.9812517827931415, 0.9874053705604631, 0.9848235380887718, 0.9855537839102215]\n"
     ]
    }
   ],
   "source": [
    "#Check best model\n",
    "nn_gs_1 = regl_1.best_estimator_\n",
    "nn_gs_2 = regl_2.best_estimator_\n",
    "nn_gs_3 = regl_3.best_estimator_\n",
    "nn_gs_4 = regl_4.best_estimator_\n",
    "gs_1_score = [nn_gs_1.score(X_test, Y_test), nn_gs_1.score(X_test_1, Y_test_1), nn_gs_1.score(X_test_2, Y_test_2),\n",
    "            nn_gs_1.score(X_test_3, Y_test_3), nn_gs_1.score(X_test_4, Y_test_4)]\n",
    "gs_2_score = [nn_gs_2.score(X_test, Y_test), nn_gs_2.score(X_test_1, Y_test_1), nn_gs_2.score(X_test_2, Y_test_2),\n",
    "            nn_gs_2.score(X_test_3, Y_test_3), nn_gs_2.score(X_test_4, Y_test_4)]\n",
    "gs_3_score = [nn_gs_3.score(X_test, Y_test), nn_gs_3.score(X_test_1, Y_test_1), nn_gs_3.score(X_test_2, Y_test_2),\n",
    "            nn_gs_3.score(X_test_3, Y_test_3), nn_gs_3.score(X_test_4, Y_test_4)]\n",
    "gs_4_score = [nn_gs_4.score(X_test, Y_test), nn_gs_4.score(X_test_1, Y_test_1), nn_gs_4.score(X_test_2, Y_test_2),\n",
    "            nn_gs_4.score(X_test_3, Y_test_3), nn_gs_4.score(X_test_4, Y_test_4)]\n",
    "'''print(np.average(gs_1_score))\n",
    "print(np.average(gs_2_score))\n",
    "print(np.average(gs_3_score))'''\n",
    "print(gs_1_score)\n",
    "print(gs_2_score)\n",
    "print(gs_3_score)\n",
    "print(gs_4_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d06e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "train_scores, test_scores = list(), list()\n",
    "for al in a:\n",
    "    nnl = MLPRegressor(solver=\"lbfgs\", max_iter=2000, hidden_layer_sizes=al, alpha=0.05)\n",
    "    nnl.fit(X_train,Y_train)\n",
    "    # evaluate on the train dataset\n",
    "    train_yhat = nnl.predict(X_train)\n",
    "    train_acc = r2_score(Y_train, train_yhat)\n",
    "    train_scores.append(train_acc)\n",
    "    # evaluate on the test dataset\n",
    "    test_yhat = nnl.predict(X_test)\n",
    "    test_acc = r2_score(Y_test, test_yhat)\n",
    "    test_scores.append(test_acc)\n",
    "    # summarize progress\n",
    "    print('>%d, train: %.3f, test: %.3f' % (al[0], train_acc, test_acc))\n",
    "\n",
    "# plot of train and test scores vs tree depth\n",
    "pyplot.plot(b, train_scores, '-o', label='Train')\n",
    "pyplot.plot(b, test_scores, '-o', label='Test')\n",
    "pyplot.legend()\n",
    "#pyplot.xscale('log')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10eb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler.inverse_transform(X_test), nn.predict(X_test))\n",
    "print(scaler.inverse_transform(X_train), nn.predict(X_train), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c10785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create gradient descent process and find optimal geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf27253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector absolute value\n",
    "def vecabs(a):\n",
    "    s = 0\n",
    "    for el in a:\n",
    "        s = s + pow(el,2)\n",
    "    return np.sqrt(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852db795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss calculation\n",
    "def loss(s, est ,g, mu_g, rg):\n",
    "    sp = abs(est.predict([g])[0])\n",
    "    return (pow((sp[0]-s[0]),2) + pow((sp[1]-s[1]), 2))\n",
    "''' + relu(abs(g[0]-mu_g[0]) - 1/2*rg[0]) + \n",
    "            relu(abs(g[1]-mu_g[1]) - 1/2*rg[1]) + relu(abs(g[2]-mu_g[2]) - 1/2*rg[2]) + \n",
    "            relu(abs(g[3]-mu_g[3]) - 1/2*rg[3]))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "280a61ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReLU\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26a5493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate single iteration of gradient descent adjustment\n",
    "def grad(s, est, g, delta, mu_g, rg):\n",
    "    del0 = np.array([delta[0], 0, 0, 0])\n",
    "    del1 = np.array([0, delta[1], 0, 0])\n",
    "    del2 = np.array([0, 0, delta[2], 0])\n",
    "    del3 = np.array([0, 0, 0, delta[3]])\n",
    "    del_l0 = loss(s, est, g + del0, mu_g, rg) - loss(s, est, g, mu_g, rg)\n",
    "    del_l1 = loss(s, est, g + del1, mu_g, rg) - loss(s, est, g, mu_g, rg)\n",
    "    del_l2 = loss(s, est, g + del2, mu_g, rg) - loss(s, est, g, mu_g, rg)\n",
    "    del_l3 = loss(s, est, g + del3, mu_g, rg) - loss(s, est, g, mu_g, rg)\n",
    "    return [del_l0/delta[0], del_l1/delta[1], del_l2/delta[2], del_l3/delta[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b2a10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find optimal g given initial g\n",
    "def opt(s, est, g_ini, delta, lam, mu_g, rg, tol, max_iter):\n",
    "    g_hat = g_ini\n",
    "    prev = 0\n",
    "    curr = loss(s, est, g_hat, mu_g, rg)\n",
    "    count = 0\n",
    "    while(abs(curr-prev) > tol and count < max_iter):\n",
    "        prev = curr\n",
    "        g_hat = g_hat - lam*np.array(grad(s, est, g_hat, delta, mu_g, rg))\n",
    "        curr = loss(s, est, g_hat, mu_g, rg)\n",
    "        count += 1\n",
    "    print(count)\n",
    "    return g_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a35b168",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553\n",
      "570\n",
      "70\n",
      "57\n",
      "83\n",
      "447\n",
      "138\n",
      "223\n",
      "39\n",
      "22\n",
      "42\n",
      "191\n",
      "166\n",
      "270\n",
      "714\n",
      "184\n",
      "191\n",
      "173\n",
      "1000\n",
      "477\n",
      "1000\n",
      "443\n",
      "202\n",
      "852\n",
      "1000\n",
      "358\n",
      "989\n",
      "42\n",
      "135\n",
      "142\n",
      "76\n",
      "25\n",
      "534\n",
      "434\n",
      "103\n",
      "494\n",
      "391\n",
      "523\n",
      "253\n",
      "345\n",
      "296\n",
      "224\n",
      "159\n",
      "1000\n",
      "448\n",
      "135\n",
      "322\n",
      "107\n",
      "352\n",
      "99\n",
      "1000\n",
      "325\n",
      "100\n",
      "313\n",
      "163\n",
      "97\n",
      "564\n",
      "558\n",
      "382\n",
      "87\n",
      "93\n",
      "291\n",
      "105\n",
      "377\n",
      "312\n",
      "1\n",
      "257\n",
      "634\n",
      "123\n",
      "246\n",
      "277\n",
      "1000\n",
      "1000\n",
      "461\n",
      "365\n",
      "108\n",
      "196\n",
      "99\n",
      "162\n",
      "279\n",
      "71\n",
      "1000\n",
      "271\n",
      "180\n",
      "348\n",
      "378\n",
      "105\n",
      "787\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "502\n",
      "1000\n",
      "139\n",
      "110\n",
      "591\n",
      "189\n",
      "23\n",
      "289\n",
      "735\n",
      "252\n",
      "531\n",
      "827\n",
      "438\n",
      "252\n",
      "378\n",
      "48\n",
      "395\n",
      "1000\n",
      "806\n",
      "117\n",
      "284\n",
      "137\n",
      "149\n",
      "587\n",
      "110\n",
      "195\n",
      "212\n",
      "161\n",
      "765\n",
      "96\n",
      "46\n",
      "235\n",
      "107\n",
      "425\n",
      "449\n",
      "441\n",
      "501\n",
      "776\n",
      "1000\n",
      "40\n",
      "613\n",
      "57\n",
      "138\n",
      "249\n",
      "396\n",
      "592\n",
      "1000\n",
      "397\n",
      "1000\n",
      "651\n",
      "702\n",
      "340\n",
      "112\n",
      "1000\n",
      "110\n",
      "127\n",
      "115\n",
      "206\n",
      "356\n",
      "407\n",
      "525\n",
      "476\n",
      "237\n",
      "101\n",
      "197\n",
      "570\n",
      "233\n",
      "345\n",
      "1000\n",
      "489\n",
      "48\n",
      "92\n",
      "397\n",
      "405\n",
      "54\n",
      "1000\n",
      "207\n",
      "347\n",
      "1000\n",
      "90\n",
      "140\n",
      "47\n",
      "229\n",
      "750\n",
      "89\n",
      "774\n",
      "195\n",
      "256\n",
      "214\n",
      "16\n",
      "338\n",
      "99\n",
      "255\n",
      "323\n",
      "139\n",
      "1000\n",
      "424\n",
      "556\n",
      "1000\n",
      "165\n",
      "206\n",
      "55\n",
      "607\n",
      "165\n",
      "361\n",
      "118\n",
      "1000\n",
      "411\n",
      "186\n",
      "251\n",
      "79\n",
      "82\n",
      "1000\n",
      "82\n",
      "206\n",
      "60\n",
      "404\n",
      "359\n",
      "287\n",
      "782\n",
      "473\n",
      "68\n",
      "89\n",
      "117\n",
      "1000\n",
      "170\n",
      "450\n",
      "265\n",
      "515\n",
      "573\n",
      "289\n",
      "107\n",
      "573\n",
      "106\n",
      "136\n",
      "183\n",
      "609\n",
      "149\n",
      "426\n",
      "8\n",
      "436\n",
      "22\n",
      "67\n",
      "182\n",
      "1000\n",
      "1000\n",
      "69\n",
      "70\n",
      "141\n",
      "485\n",
      "83\n",
      "329\n",
      "393\n",
      "197\n",
      "1000\n",
      "317\n",
      "298\n",
      "69\n",
      "863\n",
      "544\n",
      "363\n",
      "531\n",
      "92\n",
      "222\n",
      "596\n",
      "1000\n",
      "241\n",
      "166\n",
      "264\n",
      "311\n",
      "239\n",
      "476\n",
      "145\n",
      "170\n",
      "204\n",
      "747\n",
      "1000\n",
      "301\n",
      "1000\n",
      "1000\n",
      "137\n",
      "378\n",
      "42\n",
      "171\n",
      "773\n",
      "219\n",
      "112\n",
      "51\n",
      "128\n",
      "227\n",
      "324\n",
      "431\n",
      "728\n",
      "579\n",
      "42\n",
      "1000\n",
      "91\n",
      "240\n",
      "203\n",
      "207\n",
      "163\n",
      "10\n",
      "194\n",
      "1000\n",
      "195\n",
      "147\n",
      "124\n",
      "1000\n",
      "325\n",
      "208\n",
      "285\n",
      "335\n",
      "1000\n",
      "588\n",
      "616\n",
      "170\n",
      "85\n",
      "528\n",
      "196\n",
      "286\n",
      "207\n",
      "309\n",
      "1000\n",
      "671\n",
      "1000\n",
      "148\n",
      "832\n",
      "992\n",
      "362\n",
      "68\n",
      "155\n",
      "76\n",
      "38\n",
      "110\n",
      "104\n",
      "141\n",
      "656\n",
      "166\n",
      "320\n",
      "81\n",
      "660\n",
      "287\n",
      "186\n",
      "559\n",
      "165\n",
      "249\n",
      "1000\n",
      "175\n",
      "113\n",
      "58\n",
      "9\n",
      "547\n",
      "1000\n",
      "207\n",
      "343\n",
      "200\n",
      "103\n",
      "150\n",
      "362\n",
      "101\n",
      "261\n",
      "610\n",
      "374\n",
      "98\n",
      "271\n",
      "273\n",
      "139\n",
      "257\n",
      "113\n",
      "332\n",
      "559\n",
      "176\n",
      "150\n",
      "64\n",
      "1000\n",
      "303\n",
      "1000\n",
      "1000\n",
      "195\n",
      "511\n",
      "188\n",
      "189\n",
      "163\n",
      "165\n",
      "119\n",
      "1000\n",
      "73\n",
      "1000\n",
      "101\n",
      "226\n",
      "376\n",
      "448\n",
      "307\n",
      "267\n",
      "66\n",
      "206\n",
      "1000\n",
      "167\n",
      "196\n",
      "1000\n",
      "491\n",
      "330\n",
      "1000\n",
      "251\n",
      "311\n",
      "670\n",
      "185\n",
      "453\n",
      "1000\n",
      "129\n",
      "138\n",
      "167\n",
      "73\n",
      "423\n",
      "599\n",
      "267\n",
      "152\n",
      "837\n",
      "347\n",
      "248\n",
      "1000\n",
      "501\n",
      "120\n",
      "621\n",
      "660\n",
      "241\n",
      "479\n",
      "202\n",
      "43\n",
      "88\n",
      "203\n",
      "1000\n",
      "889\n",
      "124\n",
      "1000\n",
      "149\n",
      "527\n",
      "68\n",
      "34\n",
      "680\n",
      "427\n",
      "281\n",
      "182\n",
      "189\n",
      "227\n",
      "711\n",
      "331\n",
      "239\n",
      "22\n",
      "172\n",
      "369\n",
      "55\n",
      "346\n",
      "1000\n",
      "110\n",
      "192\n",
      "183\n",
      "20\n",
      "171\n",
      "269\n",
      "124\n",
      "152\n",
      "412\n",
      "775\n",
      "113\n",
      "99\n",
      "148\n",
      "276\n",
      "229\n",
      "337\n",
      "160\n",
      "682\n",
      "169\n",
      "65\n",
      "331\n",
      "244\n",
      "636\n",
      "153\n",
      "1000\n",
      "349\n",
      "1000\n",
      "236\n",
      "322\n",
      "854\n",
      "168\n",
      "1000\n",
      "263\n",
      "312\n",
      "136\n",
      "371\n",
      "328\n",
      "361\n",
      "265\n",
      "139\n",
      "25\n",
      "514\n",
      "1000\n",
      "29\n",
      "342\n",
      "154\n",
      "26\n",
      "124\n",
      "343\n",
      "262\n",
      "83\n",
      "143\n",
      "730\n",
      "221\n",
      "271\n",
      "543\n",
      "486\n",
      "999\n",
      "40\n",
      "159\n",
      "549\n",
      "125\n",
      "428\n",
      "675\n",
      "521\n",
      "125\n",
      "564\n",
      "156\n",
      "462\n",
      "222\n",
      "378\n",
      "395\n",
      "255\n",
      "335\n",
      "1000\n",
      "197\n",
      "763\n",
      "9\n",
      "77\n",
      "135\n",
      "83\n",
      "442\n",
      "312\n",
      "62\n",
      "107\n",
      "550\n",
      "491\n",
      "91\n",
      "284\n",
      "144\n",
      "211\n",
      "516\n",
      "135\n",
      "135\n",
      "418\n",
      "505\n",
      "269\n",
      "378\n",
      "262\n",
      "598\n",
      "857\n",
      "49\n",
      "90\n",
      "119\n",
      "240\n",
      "239\n",
      "158\n",
      "499\n",
      "880\n",
      "466\n",
      "758\n",
      "173\n",
      "1000\n",
      "513\n",
      "81\n",
      "747\n",
      "482\n",
      "216\n",
      "232\n",
      "268\n",
      "88\n",
      "83\n",
      "496\n",
      "321\n",
      "387\n",
      "638\n",
      "743\n",
      "97\n",
      "188\n",
      "228\n",
      "36\n",
      "35\n",
      "68\n",
      "616\n",
      "107\n",
      "246\n",
      "430\n",
      "196\n",
      "804\n",
      "194\n",
      "270\n",
      "85\n",
      "87\n",
      "208\n",
      "122\n",
      "250\n",
      "373\n",
      "486\n",
      "35\n",
      "114\n",
      "255\n",
      "572\n",
      "253\n",
      "71\n",
      "130\n",
      "1000\n",
      "541\n",
      "145\n",
      "527\n",
      "123\n",
      "826\n",
      "151\n",
      "238\n",
      "107\n",
      "231\n",
      "216\n",
      "430\n",
      "58\n",
      "766\n",
      "514\n",
      "68\n",
      "129\n",
      "454\n",
      "364\n",
      "392\n",
      "173\n",
      "396\n",
      "94\n",
      "237\n",
      "316\n",
      "463\n",
      "322\n",
      "208\n",
      "165\n",
      "304\n",
      "228\n",
      "760\n",
      "773\n",
      "593\n",
      "1000\n",
      "157\n",
      "271\n",
      "165\n",
      "295\n",
      "1000\n",
      "547\n",
      "165\n",
      "450\n",
      "944\n",
      "587\n",
      "131\n",
      "157\n",
      "1000\n",
      "217\n",
      "400\n",
      "208\n",
      "81\n",
      "337\n",
      "306\n",
      "142\n",
      "61\n",
      "225\n",
      "1000\n",
      "846\n",
      "31\n",
      "212\n",
      "220\n",
      "443\n",
      "152\n",
      "558\n",
      "640\n",
      "145\n",
      "761\n",
      "103\n",
      "372\n",
      "414\n",
      "280\n",
      "206\n",
      "7.43648416309479e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0025664 , 0.99176724]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform GD on ref model\n",
    "nn = nn_ref\n",
    "mu_g = np.mean(X_train, axis = 0)\n",
    "delta = [1/10000, 1/10000, 1/10000, 1/2000]\n",
    "g_min = X_train[0]\n",
    "loss_min = 1\n",
    "for x in X_train:\n",
    "    g = opt([0,1], nn, x, delta, 0.01, mu_g, r, 1e-5, 1e3)\n",
    "    l = loss([0,1], nn, g, mu_g, r)\n",
    "    if (l < loss_min):\n",
    "        g_min = g\n",
    "        loss_min = l\n",
    "print(loss_min)\n",
    "nn.predict([g_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5ca70bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal geometry, according to AI magic: [ 88.26645738  53.23413144  56.4085727  687.02278537]\n",
      "The spectrum predicted by the model: [[0.0025664  0.99176724]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0025664 , 0.99176724]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Present optimal reference geometry\n",
    "g_min_ref = g_min\n",
    "print(\"The optimal geometry, according to AI magic:\", scaler.inverse_transform(g_min_ref))\n",
    "print(\"The spectrum predicted by the model:\", nn.predict([g_min_ref]))\n",
    "nn_ref.predict([g_min_ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "214a047c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal simulated geometry [x1, x2, gap, he]: [100, 50, 50, 700]\n",
      "Simulated [p0, p1]: [0.006251921, 0.962076716]\n",
      "Predicted [p0, p1]: [0.00788261 0.95373031]\n",
      "Simulated loss: 0.001477261985534897\n",
      "Predicted loss: 0.002203020116910412\n",
      "Is predicted better than simulated?: NO!!\n"
     ]
    }
   ],
   "source": [
    "#Compare with best measurement in tm train dataset - real loss = 0.001477\n",
    "print(\"Optimal simulated geometry [x1, x2, gap, he]:\", [100,50,50,700])\n",
    "g0 = scaler.transform([[100,50,50,700]])\n",
    "#print(g0[0])\n",
    "sp = nn.predict(g0)[0]\n",
    "ssim = [0.006251921, 0.962076716]\n",
    "print(\"Simulated [p0, p1]:\", ssim)\n",
    "print(\"Predicted [p0, p1]:\", sp)\n",
    "ls = pow((ssim[0]-0),2) + pow((ssim[1]-1), 2)\n",
    "lp = pow((sp[0]-0),2) + pow((sp[1]-1), 2)\n",
    "print(\"Simulated loss:\", ls)\n",
    "print(\"Predicted loss:\", lp)\n",
    "if(ls>=lp):\n",
    "    print(\"Is predicted better than simulated?: YES!\")\n",
    "else:\n",
    "    print(\"Is predicted better than simulated?: NO!!\")\n",
    "\n",
    "#loss([0,1], nn, g0[0], mu_g, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "477211a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "442\n",
      "251\n",
      "497\n",
      "123\n",
      "1000\n",
      "1000\n",
      "26\n",
      "1\n",
      "16\n",
      "356\n",
      "694\n",
      "632\n",
      "626\n",
      "823\n",
      "410\n",
      "641\n",
      "168\n",
      "902\n",
      "464\n",
      "1000\n",
      "86\n",
      "98\n",
      "962\n",
      "462\n",
      "143\n",
      "87\n",
      "100\n",
      "808\n",
      "629\n",
      "46\n",
      "1000\n",
      "333\n",
      "578\n",
      "141\n",
      "147\n",
      "1000\n",
      "394\n",
      "224\n",
      "388\n",
      "812\n",
      "612\n",
      "97\n",
      "687\n",
      "57\n",
      "80\n",
      "667\n",
      "112\n",
      "1000\n",
      "139\n",
      "1000\n",
      "211\n",
      "432\n",
      "167\n",
      "813\n",
      "77\n",
      "1000\n",
      "325\n",
      "468\n",
      "108\n",
      "619\n",
      "208\n",
      "927\n",
      "195\n",
      "1000\n",
      "973\n",
      "490\n",
      "52\n",
      "159\n",
      "171\n",
      "675\n",
      "1000\n",
      "777\n",
      "215\n",
      "141\n",
      "118\n",
      "1000\n",
      "493\n",
      "63\n",
      "1000\n",
      "62\n",
      "508\n",
      "600\n",
      "976\n",
      "308\n",
      "562\n",
      "240\n",
      "359\n",
      "192\n",
      "1\n",
      "1000\n",
      "92\n",
      "839\n",
      "234\n",
      "65\n",
      "1\n",
      "310\n",
      "1000\n",
      "232\n",
      "799\n",
      "750\n",
      "14\n",
      "523\n",
      "589\n",
      "642\n",
      "847\n",
      "638\n",
      "1000\n",
      "11\n",
      "1000\n",
      "173\n",
      "377\n",
      "519\n",
      "224\n",
      "738\n",
      "128\n",
      "189\n",
      "472\n",
      "277\n",
      "204\n",
      "79\n",
      "192\n",
      "57\n",
      "636\n",
      "48\n",
      "273\n",
      "166\n",
      "176\n",
      "772\n",
      "1000\n",
      "77\n",
      "162\n",
      "22\n",
      "117\n",
      "723\n",
      "68\n",
      "95\n",
      "1000\n",
      "1000\n",
      "514\n",
      "980\n",
      "1000\n",
      "125\n",
      "520\n",
      "593\n",
      "61\n",
      "466\n",
      "204\n",
      "190\n",
      "229\n",
      "1000\n",
      "153\n",
      "95\n",
      "691\n",
      "131\n",
      "10\n",
      "548\n",
      "117\n",
      "237\n",
      "1000\n",
      "446\n",
      "355\n",
      "925\n",
      "266\n",
      "341\n",
      "81\n",
      "1000\n",
      "20\n",
      "312\n",
      "1000\n",
      "26\n",
      "142\n",
      "948\n",
      "265\n",
      "705\n",
      "197\n",
      "1\n",
      "1000\n",
      "156\n",
      "303\n",
      "33\n",
      "305\n",
      "550\n",
      "323\n",
      "285\n",
      "395\n",
      "1000\n",
      "802\n",
      "305\n",
      "1000\n",
      "209\n",
      "45\n",
      "47\n",
      "252\n",
      "385\n",
      "304\n",
      "355\n",
      "592\n",
      "477\n",
      "186\n",
      "828\n",
      "76\n",
      "664\n",
      "195\n",
      "14\n",
      "432\n",
      "69\n",
      "571\n",
      "107\n",
      "1000\n",
      "761\n",
      "182\n",
      "532\n",
      "328\n",
      "364\n",
      "176\n",
      "386\n",
      "694\n",
      "228\n",
      "510\n",
      "324\n",
      "579\n",
      "104\n",
      "486\n",
      "1000\n",
      "213\n",
      "369\n",
      "623\n",
      "657\n",
      "205\n",
      "41\n",
      "1\n",
      "56\n",
      "42\n",
      "167\n",
      "1000\n",
      "477\n",
      "1\n",
      "335\n",
      "361\n",
      "310\n",
      "266\n",
      "159\n",
      "245\n",
      "328\n",
      "1000\n",
      "356\n",
      "121\n",
      "241\n",
      "42\n",
      "636\n",
      "101\n",
      "682\n",
      "183\n",
      "1000\n",
      "47\n",
      "1000\n",
      "781\n",
      "167\n",
      "522\n",
      "178\n",
      "491\n",
      "345\n",
      "94\n",
      "219\n",
      "412\n",
      "650\n",
      "442\n",
      "369\n",
      "1000\n",
      "777\n",
      "102\n",
      "594\n",
      "1000\n",
      "90\n",
      "1000\n",
      "1000\n",
      "171\n",
      "64\n",
      "137\n",
      "246\n",
      "336\n",
      "571\n",
      "815\n",
      "809\n",
      "57\n",
      "240\n",
      "85\n",
      "222\n",
      "581\n",
      "332\n",
      "403\n",
      "12\n",
      "250\n",
      "1000\n",
      "413\n",
      "220\n",
      "91\n",
      "1000\n",
      "224\n",
      "442\n",
      "909\n",
      "346\n",
      "1000\n",
      "560\n",
      "488\n",
      "717\n",
      "96\n",
      "92\n",
      "832\n",
      "531\n",
      "277\n",
      "304\n",
      "1000\n",
      "802\n",
      "773\n",
      "132\n",
      "892\n",
      "369\n",
      "369\n",
      "76\n",
      "1000\n",
      "159\n",
      "751\n",
      "167\n",
      "1000\n",
      "1000\n",
      "25\n",
      "184\n",
      "544\n",
      "66\n",
      "262\n",
      "282\n",
      "761\n",
      "1000\n",
      "352\n",
      "44\n",
      "1000\n",
      "344\n",
      "109\n",
      "25\n",
      "1\n",
      "635\n",
      "1000\n",
      "185\n",
      "398\n",
      "442\n",
      "297\n",
      "165\n",
      "172\n",
      "151\n",
      "355\n",
      "575\n",
      "424\n",
      "518\n",
      "207\n",
      "335\n",
      "125\n",
      "379\n",
      "1000\n",
      "788\n",
      "554\n",
      "477\n",
      "1000\n",
      "63\n",
      "1000\n",
      "361\n",
      "893\n",
      "90\n",
      "223\n",
      "177\n",
      "815\n",
      "367\n",
      "429\n",
      "278\n",
      "105\n",
      "356\n",
      "96\n",
      "168\n",
      "1000\n",
      "592\n",
      "210\n",
      "208\n",
      "117\n",
      "1000\n",
      "554\n",
      "273\n",
      "562\n",
      "455\n",
      "534\n",
      "176\n",
      "241\n",
      "626\n",
      "212\n",
      "179\n",
      "168\n",
      "857\n",
      "161\n",
      "525\n",
      "1000\n",
      "220\n",
      "811\n",
      "158\n",
      "21\n",
      "1000\n",
      "275\n",
      "946\n",
      "101\n",
      "302\n",
      "545\n",
      "390\n",
      "582\n",
      "201\n",
      "253\n",
      "979\n",
      "653\n",
      "326\n",
      "286\n",
      "78\n",
      "193\n",
      "265\n",
      "599\n",
      "1000\n",
      "953\n",
      "250\n",
      "528\n",
      "146\n",
      "632\n",
      "115\n",
      "738\n",
      "777\n",
      "242\n",
      "248\n",
      "155\n",
      "393\n",
      "608\n",
      "558\n",
      "1000\n",
      "107\n",
      "454\n",
      "1000\n",
      "1000\n",
      "66\n",
      "1000\n",
      "1000\n",
      "418\n",
      "556\n",
      "211\n",
      "628\n",
      "140\n",
      "600\n",
      "303\n",
      "213\n",
      "258\n",
      "631\n",
      "1000\n",
      "408\n",
      "134\n",
      "245\n",
      "336\n",
      "352\n",
      "348\n",
      "279\n",
      "526\n",
      "347\n",
      "533\n",
      "240\n",
      "872\n",
      "574\n",
      "494\n",
      "215\n",
      "1000\n",
      "248\n",
      "388\n",
      "880\n",
      "296\n",
      "1000\n",
      "972\n",
      "1000\n",
      "1000\n",
      "276\n",
      "300\n",
      "67\n",
      "213\n",
      "199\n",
      "553\n",
      "706\n",
      "1000\n",
      "160\n",
      "44\n",
      "294\n",
      "214\n",
      "387\n",
      "479\n",
      "70\n",
      "100\n",
      "164\n",
      "114\n",
      "159\n",
      "191\n",
      "1000\n",
      "375\n",
      "1000\n",
      "751\n",
      "547\n",
      "112\n",
      "725\n",
      "317\n",
      "86\n",
      "302\n",
      "91\n",
      "212\n",
      "743\n",
      "606\n",
      "76\n",
      "289\n",
      "145\n",
      "754\n",
      "239\n",
      "1000\n",
      "109\n",
      "1000\n",
      "500\n",
      "273\n",
      "634\n",
      "212\n",
      "157\n",
      "753\n",
      "67\n",
      "251\n",
      "579\n",
      "146\n",
      "323\n",
      "1000\n",
      "370\n",
      "103\n",
      "485\n",
      "1000\n",
      "334\n",
      "204\n",
      "1000\n",
      "81\n",
      "314\n",
      "449\n",
      "1000\n",
      "196\n",
      "408\n",
      "1000\n",
      "249\n",
      "615\n",
      "430\n",
      "456\n",
      "662\n",
      "960\n",
      "959\n",
      "92\n",
      "97\n",
      "14\n",
      "92\n",
      "92\n",
      "800\n",
      "21\n",
      "573\n",
      "426\n",
      "1000\n",
      "411\n",
      "1000\n",
      "613\n",
      "1000\n",
      "306\n",
      "449\n",
      "532\n",
      "426\n",
      "586\n",
      "189\n",
      "577\n",
      "48\n",
      "62\n",
      "103\n",
      "1000\n",
      "356\n",
      "43\n",
      "420\n",
      "650\n",
      "313\n",
      "135\n",
      "526\n",
      "134\n",
      "364\n",
      "1000\n",
      "199\n",
      "353\n",
      "44\n",
      "1000\n",
      "179\n",
      "331\n",
      "330\n",
      "772\n",
      "81\n",
      "89\n",
      "709\n",
      "456\n",
      "792\n",
      "410\n",
      "254\n",
      "323\n",
      "176\n",
      "575\n",
      "255\n",
      "224\n",
      "254\n",
      "201\n",
      "839\n",
      "374\n",
      "285\n",
      "166\n",
      "105\n",
      "1000\n",
      "367\n",
      "360\n",
      "134\n",
      "322\n",
      "225\n",
      "356\n",
      "54\n",
      "271\n",
      "214\n",
      "383\n",
      "370\n",
      "307\n",
      "152\n",
      "938\n",
      "979\n",
      "184\n",
      "1000\n",
      "380\n",
      "1000\n",
      "799\n",
      "854\n",
      "1\n",
      "111\n",
      "223\n",
      "1000\n",
      "1000\n",
      "457\n",
      "43\n",
      "171\n",
      "1000\n",
      "97\n",
      "102\n",
      "170\n",
      "369\n",
      "517\n",
      "48\n",
      "127\n",
      "69\n",
      "435\n",
      "512\n",
      "1000\n",
      "7\n",
      "215\n",
      "1000\n",
      "564\n",
      "198\n",
      "351\n",
      "65\n",
      "286\n",
      "103\n",
      "65\n",
      "334\n",
      "314\n",
      "470\n",
      "533\n",
      "0.000671546773115535\n",
      "The optimal CV geometry, according to AI magic: [ 99.13901478  47.30292501  58.6425256  695.73479518]\n",
      "The spectrum predicted by the model: [[-0.02851168  0.96246425]]\n"
     ]
    }
   ],
   "source": [
    "#Perform gradient descent for the smaller model\n",
    "g_min = X_train[0]\n",
    "loss_min = 1\n",
    "for x in X_train:\n",
    "    g = opt([0,1], nn_gs_4, x, delta, 0.01, mu_g, r, 1e-5, 1e3)\n",
    "    l = loss([0,1], nn_gs_4, g, mu_g, r)\n",
    "    if (l < loss_min):\n",
    "        g_min = g\n",
    "        loss_min = l\n",
    "print(loss_min)\n",
    "nn.predict([g_min])\n",
    "#Present optimal CV geometry\n",
    "g_min_ref = g_min\n",
    "print(\"The optimal CV geometry, according to AI magic:\", scaler.inverse_transform(g_min))\n",
    "print(\"The spectrum predicted by the model:\", nn.predict([g_min]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "222b5fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553\n",
      "570\n",
      "70\n",
      "57\n",
      "83\n",
      "447\n",
      "138\n",
      "223\n",
      "39\n",
      "22\n",
      "42\n",
      "191\n",
      "166\n",
      "270\n",
      "714\n",
      "184\n",
      "191\n",
      "173\n",
      "2095\n",
      "477\n",
      "3376\n",
      "443\n",
      "202\n",
      "852\n",
      "2221\n",
      "358\n",
      "989\n",
      "42\n",
      "135\n",
      "142\n",
      "76\n",
      "25\n",
      "534\n",
      "434\n",
      "103\n",
      "494\n",
      "391\n",
      "523\n",
      "253\n",
      "345\n",
      "296\n",
      "224\n",
      "159\n",
      "5649\n",
      "448\n",
      "135\n",
      "322\n",
      "107\n",
      "352\n",
      "99\n",
      "1734\n",
      "325\n",
      "100\n",
      "313\n",
      "163\n",
      "97\n",
      "564\n",
      "558\n",
      "382\n",
      "87\n",
      "93\n",
      "291\n",
      "105\n",
      "377\n",
      "312\n",
      "1\n",
      "257\n",
      "634\n",
      "123\n",
      "246\n",
      "277\n",
      "1279\n",
      "5034\n",
      "461\n",
      "365\n",
      "108\n",
      "196\n",
      "99\n",
      "162\n",
      "279\n",
      "71\n",
      "2889\n",
      "271\n",
      "180\n",
      "348\n",
      "378\n",
      "105\n",
      "787\n",
      "1798\n",
      "1562\n",
      "1032\n",
      "502\n",
      "2562\n",
      "139\n",
      "110\n",
      "591\n",
      "189\n",
      "23\n",
      "289\n",
      "735\n",
      "252\n",
      "531\n",
      "827\n",
      "438\n",
      "252\n",
      "378\n",
      "48\n",
      "395\n",
      "1247\n",
      "806\n",
      "117\n",
      "284\n",
      "137\n",
      "149\n",
      "587\n",
      "110\n",
      "195\n",
      "212\n",
      "161\n",
      "765\n",
      "96\n",
      "46\n",
      "235\n",
      "107\n",
      "425\n",
      "449\n",
      "441\n",
      "501\n",
      "776\n",
      "2942\n",
      "40\n",
      "613\n",
      "57\n",
      "138\n",
      "249\n",
      "396\n",
      "592\n",
      "1878\n",
      "397\n",
      "1052\n",
      "651\n",
      "702\n",
      "340\n",
      "112\n",
      "1544\n",
      "110\n",
      "127\n",
      "115\n",
      "206\n",
      "356\n",
      "407\n",
      "525\n",
      "476\n",
      "237\n",
      "101\n",
      "197\n",
      "570\n",
      "233\n",
      "345\n",
      "5913\n",
      "489\n",
      "48\n",
      "92\n",
      "397\n",
      "405\n",
      "54\n",
      "1496\n",
      "207\n",
      "347\n",
      "2660\n",
      "90\n",
      "140\n",
      "47\n",
      "229\n",
      "750\n",
      "89\n",
      "774\n",
      "195\n",
      "256\n",
      "214\n",
      "16\n",
      "338\n",
      "99\n",
      "255\n",
      "323\n",
      "139\n",
      "2951\n",
      "424\n",
      "556\n",
      "1022\n",
      "165\n",
      "206\n",
      "55\n",
      "607\n",
      "165\n",
      "361\n",
      "118\n",
      "2651\n",
      "411\n",
      "186\n",
      "251\n",
      "79\n",
      "82\n",
      "1160\n",
      "82\n",
      "206\n",
      "60\n",
      "404\n",
      "359\n",
      "287\n",
      "782\n",
      "473\n",
      "68\n",
      "89\n",
      "117\n",
      "1336\n",
      "170\n",
      "450\n",
      "265\n",
      "515\n",
      "573\n",
      "289\n",
      "107\n",
      "573\n",
      "106\n",
      "136\n",
      "183\n",
      "609\n",
      "149\n",
      "426\n",
      "8\n",
      "436\n",
      "22\n",
      "67\n",
      "182\n",
      "2509\n",
      "2804\n",
      "69\n",
      "70\n",
      "141\n",
      "485\n",
      "83\n",
      "329\n",
      "393\n",
      "197\n",
      "2677\n",
      "317\n",
      "298\n",
      "69\n",
      "863\n",
      "544\n",
      "363\n",
      "531\n",
      "92\n",
      "222\n",
      "596\n",
      "3037\n",
      "241\n",
      "166\n",
      "264\n",
      "311\n",
      "239\n",
      "476\n",
      "145\n",
      "170\n",
      "204\n",
      "747\n",
      "2378\n",
      "301\n",
      "1637\n",
      "1544\n",
      "137\n",
      "378\n",
      "42\n",
      "171\n",
      "773\n",
      "219\n",
      "112\n",
      "51\n",
      "128\n",
      "227\n",
      "324\n",
      "431\n",
      "728\n",
      "579\n",
      "42\n",
      "1913\n",
      "91\n",
      "240\n",
      "203\n",
      "207\n",
      "163\n",
      "10\n",
      "194\n",
      "1148\n",
      "195\n",
      "147\n",
      "124\n",
      "2620\n",
      "325\n",
      "208\n",
      "285\n",
      "335\n",
      "1665\n",
      "588\n",
      "616\n",
      "170\n",
      "85\n",
      "528\n",
      "196\n",
      "286\n",
      "207\n",
      "309\n",
      "2802\n",
      "671\n",
      "1487\n",
      "148\n",
      "832\n",
      "992\n",
      "362\n",
      "68\n",
      "155\n",
      "76\n",
      "38\n",
      "110\n",
      "104\n",
      "141\n",
      "656\n",
      "166\n",
      "320\n",
      "81\n",
      "660\n",
      "287\n",
      "186\n",
      "559\n",
      "165\n",
      "249\n",
      "1298\n",
      "175\n",
      "113\n",
      "58\n",
      "9\n",
      "547\n",
      "2587\n",
      "207\n",
      "343\n",
      "200\n",
      "103\n",
      "150\n",
      "362\n",
      "101\n",
      "261\n",
      "610\n",
      "374\n",
      "98\n",
      "271\n",
      "273\n",
      "139\n",
      "257\n",
      "113\n",
      "332\n",
      "559\n",
      "176\n",
      "150\n",
      "64\n",
      "2768\n",
      "303\n",
      "1085\n",
      "1213\n",
      "195\n",
      "511\n",
      "188\n",
      "189\n",
      "163\n",
      "165\n",
      "119\n",
      "1464\n",
      "73\n",
      "2801\n",
      "101\n",
      "226\n",
      "376\n",
      "448\n",
      "307\n",
      "267\n",
      "66\n",
      "206\n",
      "3277\n",
      "167\n",
      "196\n",
      "1360\n",
      "491\n",
      "330\n",
      "1547\n",
      "251\n",
      "311\n",
      "670\n",
      "185\n",
      "453\n",
      "3004\n",
      "129\n",
      "138\n",
      "167\n",
      "73\n",
      "423\n",
      "599\n",
      "267\n",
      "152\n",
      "837\n",
      "347\n",
      "248\n",
      "1313\n",
      "501\n",
      "120\n",
      "621\n",
      "660\n",
      "241\n",
      "479\n",
      "202\n",
      "43\n",
      "88\n",
      "203\n",
      "3293\n",
      "889\n",
      "124\n",
      "1453\n",
      "149\n",
      "527\n",
      "68\n",
      "34\n",
      "680\n",
      "427\n",
      "281\n",
      "182\n",
      "189\n",
      "227\n",
      "711\n",
      "331\n",
      "239\n",
      "22\n",
      "172\n",
      "369\n",
      "55\n",
      "346\n",
      "2847\n",
      "110\n",
      "192\n",
      "183\n",
      "20\n",
      "171\n",
      "269\n",
      "124\n",
      "152\n",
      "412\n",
      "775\n",
      "113\n",
      "99\n",
      "148\n",
      "276\n",
      "229\n",
      "337\n",
      "160\n",
      "682\n",
      "169\n",
      "65\n",
      "331\n",
      "244\n",
      "636\n",
      "153\n",
      "1693\n",
      "349\n",
      "2505\n",
      "236\n",
      "322\n",
      "854\n",
      "168\n",
      "3257\n",
      "263\n",
      "312\n",
      "136\n",
      "371\n",
      "328\n",
      "361\n",
      "265\n",
      "139\n",
      "25\n",
      "514\n",
      "3036\n",
      "29\n",
      "342\n",
      "154\n",
      "26\n",
      "124\n",
      "343\n",
      "262\n",
      "83\n",
      "143\n",
      "730\n",
      "221\n",
      "271\n",
      "543\n",
      "486\n",
      "999\n",
      "40\n",
      "159\n",
      "549\n",
      "125\n",
      "428\n",
      "675\n",
      "521\n",
      "125\n",
      "564\n",
      "156\n",
      "462\n",
      "222\n",
      "378\n",
      "395\n",
      "255\n",
      "335\n",
      "1929\n",
      "197\n",
      "763\n",
      "9\n",
      "77\n",
      "135\n",
      "83\n",
      "442\n",
      "312\n",
      "62\n",
      "107\n",
      "550\n",
      "491\n",
      "91\n",
      "284\n",
      "144\n",
      "211\n",
      "516\n",
      "135\n",
      "135\n",
      "418\n",
      "505\n",
      "269\n",
      "378\n",
      "262\n",
      "598\n",
      "857\n",
      "49\n",
      "90\n",
      "119\n",
      "240\n",
      "239\n",
      "158\n",
      "499\n",
      "880\n",
      "466\n",
      "758\n",
      "173\n",
      "7281\n",
      "513\n",
      "81\n",
      "747\n",
      "482\n",
      "216\n",
      "232\n",
      "268\n",
      "88\n",
      "83\n",
      "496\n",
      "321\n",
      "387\n",
      "638\n",
      "743\n",
      "97\n",
      "188\n",
      "228\n",
      "36\n",
      "35\n",
      "68\n",
      "616\n",
      "107\n",
      "246\n",
      "430\n",
      "196\n",
      "804\n",
      "194\n",
      "270\n",
      "85\n",
      "87\n",
      "208\n",
      "122\n",
      "250\n",
      "373\n",
      "486\n",
      "35\n",
      "114\n",
      "255\n",
      "572\n",
      "253\n",
      "71\n",
      "130\n",
      "2205\n",
      "541\n",
      "145\n",
      "527\n",
      "123\n",
      "826\n",
      "151\n",
      "238\n",
      "107\n",
      "231\n",
      "216\n",
      "430\n",
      "58\n",
      "766\n",
      "514\n",
      "68\n",
      "129\n",
      "454\n",
      "364\n",
      "392\n",
      "173\n",
      "396\n",
      "94\n",
      "237\n",
      "316\n",
      "463\n",
      "322\n",
      "208\n",
      "165\n",
      "304\n",
      "228\n",
      "760\n",
      "773\n",
      "593\n",
      "1232\n",
      "157\n",
      "271\n",
      "165\n",
      "295\n",
      "1131\n",
      "547\n",
      "165\n",
      "450\n",
      "944\n",
      "587\n",
      "131\n",
      "157\n",
      "2306\n",
      "217\n",
      "400\n",
      "208\n",
      "81\n",
      "337\n",
      "306\n",
      "142\n",
      "61\n",
      "225\n",
      "2396\n",
      "846\n",
      "31\n",
      "212\n",
      "220\n",
      "443\n",
      "152\n",
      "558\n",
      "640\n",
      "145\n",
      "761\n",
      "103\n",
      "372\n",
      "414\n",
      "280\n",
      "206\n",
      "7.43648416309479e-05\n",
      "The optimal reference geometry, according to AI magic, 10000 tries: [ 88.26645738  53.23413144  56.4085727  687.02278537]\n",
      "The spectrum predicted by the model: [[0.0025664  0.99176724]]\n"
     ]
    }
   ],
   "source": [
    "#Check gradient descent for 10000 tries - better?\n",
    "nn = nn_ref\n",
    "mu_g = np.mean(X_train, axis = 0)\n",
    "delta = [1/10000, 1/10000, 1/10000, 1/2000]\n",
    "g_min = X_train[0]\n",
    "loss_min = 1\n",
    "for x in X_train:\n",
    "    g = opt([0,1], nn, x, delta, 0.01, mu_g, r, 1e-5, 1e4)\n",
    "    l = loss([0,1], nn, g, mu_g, r)\n",
    "    if (l < loss_min):\n",
    "        g_min = g\n",
    "        loss_min = l\n",
    "print(loss_min)\n",
    "nn.predict([g_min])\n",
    "print(\"The optimal reference geometry, according to AI magic, 10000 tries:\", scaler.inverse_transform(g_min))\n",
    "print(\"The spectrum predicted by the model:\", nn.predict([g_min]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abf90d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977\n",
      "442\n",
      "251\n",
      "497\n",
      "123\n",
      "1240\n",
      "1180\n",
      "26\n",
      "1\n",
      "16\n",
      "356\n",
      "694\n",
      "632\n",
      "626\n",
      "823\n",
      "410\n",
      "641\n",
      "168\n",
      "902\n",
      "464\n",
      "8912\n",
      "86\n",
      "98\n",
      "962\n",
      "462\n",
      "143\n",
      "87\n",
      "100\n",
      "808\n",
      "629\n",
      "46\n",
      "1151\n",
      "333\n",
      "578\n",
      "141\n",
      "147\n",
      "2446\n",
      "394\n",
      "224\n",
      "388\n",
      "812\n",
      "612\n",
      "97\n",
      "687\n",
      "57\n",
      "80\n",
      "667\n",
      "112\n",
      "3400\n",
      "139\n",
      "2924\n",
      "211\n",
      "432\n",
      "167\n",
      "813\n",
      "77\n",
      "2004\n",
      "325\n",
      "468\n",
      "108\n",
      "619\n",
      "208\n",
      "927\n",
      "195\n",
      "1302\n",
      "973\n",
      "490\n",
      "52\n",
      "159\n",
      "171\n",
      "675\n",
      "2247\n",
      "777\n",
      "215\n",
      "141\n",
      "118\n",
      "1230\n",
      "493\n",
      "63\n",
      "1567\n",
      "62\n",
      "508\n",
      "600\n",
      "976\n",
      "308\n",
      "562\n",
      "240\n",
      "359\n",
      "192\n",
      "1\n",
      "3184\n",
      "92\n",
      "839\n",
      "234\n",
      "65\n",
      "1\n",
      "310\n",
      "1314\n",
      "232\n",
      "799\n",
      "750\n",
      "14\n",
      "523\n",
      "589\n",
      "642\n",
      "847\n",
      "638\n",
      "1066\n",
      "11\n",
      "1012\n",
      "173\n",
      "377\n",
      "519\n",
      "224\n",
      "738\n",
      "128\n",
      "189\n",
      "472\n",
      "277\n",
      "204\n",
      "79\n",
      "192\n",
      "57\n",
      "636\n",
      "48\n",
      "273\n",
      "166\n",
      "176\n",
      "772\n",
      "4623\n",
      "77\n",
      "162\n",
      "22\n",
      "117\n",
      "723\n",
      "68\n",
      "95\n",
      "3230\n",
      "2438\n",
      "514\n",
      "980\n",
      "5225\n",
      "125\n",
      "520\n",
      "593\n",
      "61\n",
      "466\n",
      "204\n",
      "190\n",
      "229\n",
      "1940\n",
      "153\n",
      "95\n",
      "691\n",
      "131\n",
      "10\n",
      "548\n",
      "117\n",
      "237\n",
      "6435\n",
      "446\n",
      "355\n",
      "925\n",
      "266\n",
      "341\n",
      "81\n",
      "1372\n",
      "20\n",
      "312\n",
      "3601\n",
      "26\n",
      "142\n",
      "948\n",
      "265\n",
      "705\n",
      "197\n",
      "1\n",
      "1221\n",
      "156\n",
      "303\n",
      "33\n",
      "305\n",
      "550\n",
      "323\n",
      "285\n",
      "395\n",
      "4901\n",
      "802\n",
      "305\n",
      "1138\n",
      "209\n",
      "45\n",
      "47\n",
      "252\n",
      "385\n",
      "304\n",
      "355\n",
      "592\n",
      "477\n",
      "186\n",
      "828\n",
      "76\n",
      "664\n",
      "195\n",
      "14\n",
      "432\n",
      "69\n",
      "571\n",
      "107\n",
      "1629\n",
      "761\n",
      "182\n",
      "532\n",
      "328\n",
      "364\n",
      "176\n",
      "386\n",
      "694\n",
      "228\n",
      "510\n",
      "324\n",
      "579\n",
      "104\n",
      "486\n",
      "1656\n",
      "213\n",
      "369\n",
      "623\n",
      "657\n",
      "205\n",
      "41\n",
      "1\n",
      "56\n",
      "42\n",
      "167\n",
      "2751\n",
      "477\n",
      "1\n",
      "335\n",
      "361\n",
      "310\n",
      "266\n",
      "159\n",
      "245\n",
      "328\n",
      "3296\n",
      "356\n",
      "121\n",
      "241\n",
      "42\n",
      "636\n",
      "101\n",
      "682\n",
      "183\n",
      "3819\n",
      "47\n",
      "7188\n",
      "781\n",
      "167\n",
      "522\n",
      "178\n",
      "491\n",
      "345\n",
      "94\n",
      "219\n",
      "412\n",
      "650\n",
      "442\n",
      "369\n",
      "4236\n",
      "777\n",
      "102\n",
      "594\n",
      "8003\n",
      "90\n",
      "2570\n",
      "1636\n",
      "171\n",
      "64\n",
      "137\n",
      "246\n",
      "336\n",
      "571\n",
      "815\n",
      "809\n",
      "57\n",
      "240\n",
      "85\n",
      "222\n",
      "581\n",
      "332\n",
      "403\n",
      "12\n",
      "250\n",
      "3220\n",
      "413\n",
      "220\n",
      "91\n",
      "1622\n",
      "224\n",
      "442\n",
      "909\n",
      "346\n",
      "2840\n",
      "560\n",
      "488\n",
      "717\n",
      "96\n",
      "92\n",
      "832\n",
      "531\n",
      "277\n",
      "304\n",
      "3241\n",
      "802\n",
      "773\n",
      "132\n",
      "892\n",
      "369\n",
      "369\n",
      "76\n",
      "1183\n",
      "159\n",
      "751\n",
      "167\n",
      "1008\n",
      "1194\n",
      "25\n",
      "184\n",
      "544\n",
      "66\n",
      "262\n",
      "282\n",
      "761\n",
      "3868\n",
      "352\n",
      "44\n",
      "2868\n",
      "344\n",
      "109\n",
      "25\n",
      "1\n",
      "635\n",
      "6195\n",
      "185\n",
      "398\n",
      "442\n",
      "297\n",
      "165\n",
      "172\n",
      "151\n",
      "355\n",
      "575\n",
      "424\n",
      "518\n",
      "207\n",
      "335\n",
      "125\n",
      "379\n",
      "2846\n",
      "788\n",
      "554\n",
      "477\n",
      "3473\n",
      "63\n",
      "7504\n",
      "361\n",
      "893\n",
      "90\n",
      "223\n",
      "177\n",
      "815\n",
      "367\n",
      "429\n",
      "278\n",
      "105\n",
      "356\n",
      "96\n",
      "168\n",
      "1755\n",
      "592\n",
      "210\n",
      "208\n",
      "117\n",
      "1525\n",
      "554\n",
      "273\n",
      "562\n",
      "455\n",
      "534\n",
      "176\n",
      "241\n",
      "626\n",
      "212\n",
      "179\n",
      "168\n",
      "857\n",
      "161\n",
      "525\n",
      "3993\n",
      "220\n",
      "811\n",
      "158\n",
      "21\n",
      "1424\n",
      "275\n",
      "946\n",
      "101\n",
      "302\n",
      "545\n",
      "390\n",
      "582\n",
      "201\n",
      "253\n",
      "979\n",
      "653\n",
      "326\n",
      "286\n",
      "78\n",
      "193\n",
      "265\n",
      "599\n",
      "8130\n",
      "953\n",
      "250\n",
      "528\n",
      "146\n",
      "632\n",
      "115\n",
      "738\n",
      "777\n",
      "242\n",
      "248\n",
      "155\n",
      "393\n",
      "608\n",
      "558\n",
      "1409\n",
      "107\n",
      "454\n",
      "1167\n",
      "1483\n",
      "66\n",
      "1211\n",
      "1333\n",
      "418\n",
      "556\n",
      "211\n",
      "628\n",
      "140\n",
      "600\n",
      "303\n",
      "213\n",
      "258\n",
      "631\n",
      "1273\n",
      "408\n",
      "134\n",
      "245\n",
      "336\n",
      "352\n",
      "348\n",
      "279\n",
      "526\n",
      "347\n",
      "533\n",
      "240\n",
      "872\n",
      "574\n",
      "494\n",
      "215\n",
      "2113\n",
      "248\n",
      "388\n",
      "880\n",
      "296\n",
      "1976\n",
      "972\n",
      "2914\n",
      "1584\n",
      "276\n",
      "300\n",
      "67\n",
      "213\n",
      "199\n",
      "553\n",
      "706\n",
      "4008\n",
      "160\n",
      "44\n",
      "294\n",
      "214\n",
      "387\n",
      "479\n",
      "70\n",
      "100\n",
      "164\n",
      "114\n",
      "159\n",
      "191\n",
      "1083\n",
      "375\n",
      "1051\n",
      "751\n",
      "547\n",
      "112\n",
      "725\n",
      "317\n",
      "86\n",
      "302\n",
      "91\n",
      "212\n",
      "743\n",
      "606\n",
      "76\n",
      "289\n",
      "145\n",
      "754\n",
      "239\n",
      "6441\n",
      "109\n",
      "1091\n",
      "500\n",
      "273\n",
      "634\n",
      "212\n",
      "157\n",
      "753\n",
      "67\n",
      "251\n",
      "579\n",
      "146\n",
      "323\n",
      "2270\n",
      "370\n",
      "103\n",
      "485\n",
      "1016\n",
      "334\n",
      "204\n",
      "1080\n",
      "81\n",
      "314\n",
      "449\n",
      "1200\n",
      "196\n",
      "408\n",
      "1898\n",
      "249\n",
      "615\n",
      "430\n",
      "456\n",
      "662\n",
      "960\n",
      "959\n",
      "92\n",
      "97\n",
      "14\n",
      "92\n",
      "92\n",
      "800\n",
      "21\n",
      "573\n",
      "426\n",
      "1043\n",
      "411\n",
      "1299\n",
      "613\n",
      "4107\n",
      "306\n",
      "449\n",
      "532\n",
      "426\n",
      "586\n",
      "189\n",
      "577\n",
      "48\n",
      "62\n",
      "103\n",
      "1019\n",
      "356\n",
      "43\n",
      "420\n",
      "650\n",
      "313\n",
      "135\n",
      "526\n",
      "134\n",
      "364\n",
      "1551\n",
      "199\n",
      "353\n",
      "44\n",
      "2042\n",
      "179\n",
      "331\n",
      "330\n",
      "772\n",
      "81\n",
      "89\n",
      "709\n",
      "456\n",
      "792\n",
      "410\n",
      "254\n",
      "323\n",
      "176\n",
      "575\n",
      "255\n",
      "224\n",
      "254\n",
      "201\n",
      "839\n",
      "374\n",
      "285\n",
      "166\n",
      "105\n",
      "2085\n",
      "367\n",
      "360\n",
      "134\n",
      "322\n",
      "225\n",
      "356\n",
      "54\n",
      "271\n",
      "214\n",
      "383\n",
      "370\n",
      "307\n",
      "152\n",
      "938\n",
      "979\n",
      "184\n",
      "4159\n",
      "380\n",
      "2394\n",
      "799\n",
      "854\n",
      "1\n",
      "111\n",
      "223\n",
      "1085\n",
      "1600\n",
      "457\n",
      "43\n",
      "171\n",
      "2780\n",
      "97\n",
      "102\n",
      "170\n",
      "369\n",
      "517\n",
      "48\n",
      "127\n",
      "69\n",
      "435\n",
      "512\n",
      "1302\n",
      "7\n",
      "215\n",
      "1912\n",
      "564\n",
      "198\n",
      "351\n",
      "65\n",
      "286\n",
      "103\n",
      "65\n",
      "334\n",
      "314\n",
      "470\n",
      "533\n",
      "0.000671546773115535\n",
      "The optimal CV geometry, according to AI magic, 10000 tries: [ 99.13901478  47.30292501  58.6425256  695.73479518]\n",
      "The spectrum predicted by the model: [[-0.02851168  0.96246425]]\n"
     ]
    }
   ],
   "source": [
    "#Check gradient descent for 10000 tries - better?\n",
    "g_min = X_train[0]\n",
    "loss_min = 1\n",
    "for x in X_train:\n",
    "    g = opt([0,1], nn_gs_4, x, delta, 0.01, mu_g, r, 1e-5, 1e4)\n",
    "    l = loss([0,1], nn_gs_4, g, mu_g, r)\n",
    "    if (l < loss_min):\n",
    "        g_min = g\n",
    "        loss_min = l\n",
    "print(loss_min)\n",
    "nn.predict([g_min])\n",
    "#Present optimal CV geometry\n",
    "g_min_ref = g_min\n",
    "print(\"The optimal CV geometry, according to AI magic, 10000 tries:\", scaler.inverse_transform(g_min))\n",
    "print(\"The spectrum predicted by the model:\", nn.predict([g_min]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc26e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
